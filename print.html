<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>teja&#x27;s notes</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
                <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item "><a href="Preface.html">Preface</a></li><li class="chapter-item "><a href="N_Linux_Networking.html">N. Linux_Networking</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="N/1_setup_qemu.html">N1. Setup Qemu</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="N/1_setup_uml.html">N1. Setup UML (older)</a></li></ol></li><li class="chapter-item "><a href="N/2_Packet_RX_Basic.html">N2. Packet RX path 1 : Basic</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="N/2_1_top_half.html">N2.1 Enter the Core, top half processing</a></li><li class="chapter-item "><a href="N/2_2_softirq_sched.html">N2.2 Softirqs, Softirq Scheduling (OPTIONAL)</a></li><li class="chapter-item "><a href="N/2_3_rps_rss.html">N2.3 Packet Steering (RSS and RPS) (OPTIONAL)</a></li><li class="chapter-item "><a href="N/2_4_softirq_netrx.html">N2.4 Softirq NET_RX</a></li><li class="chapter-item "><a href="N/2_5_netif_receive_skb_core.html">N2.5 __netif_receive_skb_core</a></li><li class="chapter-item "><a href="N/2_6_ip_processing.html">N2.6 IP Processing</a></li><li class="chapter-item "><a href="N/2_7_udp_processing.html">N2.7 UDP Processing</a></li></ol></li><li class="chapter-item "><a href="N/3_Packet_TX_Basic.html">N3. Packet TX path 1 : Basic</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="N/3_1-3_sendmsg_from_userspace.html">N3.1-3.2 sendmsg() from userspace</a></li><li class="chapter-item "><a href="N/3_3-4_alloc_and_send_skb.html">N3.3-3.4 alloc skb and send_skb</a></li><li class="chapter-item "><a href="N/3_5-8_net_tx_and_driver_xmit.html">N3.5-3.8 NET_TX and driver xmit</a></li></ol></li><li class="chapter-item "><a href="N/4_Socket_Programming_BTS.html">N4. (WIP) Socket Programming BTS</a></li><li class="chapter-item "><a href="N/5_Netfilter_Internals.html">N5. (WIP) Netfilter Internals</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="N/5_1_rule_matching.html">N5.1 Rule Matching</a></li><li class="chapter-item "><a href="N/5_2_rule_deconstruction.html">N5.2 Rule deconstruction</a></li><li class="chapter-item "><a href="N/5_3_Adding_tables_chains_rules_userspace.html">N5.3 Adding tables, chains, rules (userspace)</a></li><li class="chapter-item "><a href="N/5_4_Adding_tables_chains_rules_kernel.html">N5.4 Adding tables, chains, rules (kernel)</a></li><li class="chapter-item "><a href="N/5_5_Atomic_transactions.html">N5.5 Atomic Transactions</a></li><li class="chapter-item "><div>N5.6 Sets</div></li><li class="chapter-item "><div>N5.7 Maps, vmaps</div></li><li class="chapter-item "><div>N5.8 Performance comparison</div></li></ol></li></ol></li><li class="chapter-item "><a href="M_Miscellaneous.html">M. Miscellaneous</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="M/1_CSE222a_Notes.html">CSE 222a, Notes</a></li><li class="chapter-item "><a href="M/2_Cache_Side_Channel_Attacks.html">Cache Side Channel Attacks</a></li><li class="chapter-item "><a href="M/3_Memory_Models.html">Memory Models</a></li></ol></li><li class="chapter-item "><a href="P_Papers.html">P.Papers</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="P/1_ML_sys.html">ML Sys</a></li></ol></li><li class="chapter-item "><a href="Appendix.html">A. Appendix</a></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">teja&#x27;s notes</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="0-preface"><a class="header" href="#0-preface">0. Preface</a></h1>
<ol>
<li>
<p>This is a simple collection of some of my notes. Some parts are incomplete, I'll
mark them with a ​&quot;WIP&quot;​ tag.</p>
</li>
<li>
<p>No license. I am doing this for myself. If you find it helpful, that is great.</p>
</li>
<li>
<p>Please send any feedback/errors to tteja2010 at gmail dot com .</p>
</li>
<li>
<p>I went through the Linux code and then later read/understood OS concepts. My way of looking at OS related topics is hence biased towards Linux, which may make my notes weird/unnatural.</p>
</li>
<li>
<p>I like my notes to be very simple. If I were to forget the past couple of years of my life due to an accident, I should still be able to catch up by  going through my notes (Assuming I discover that I had written these notes) That is how simple it should be. I don't want to assume anything about the reader (my amnesiac self who just completed his bachelors) while writing them.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux-networking-notes"><a class="header" href="#linux-networking-notes">Linux Networking Notes</a></h1>
<p>This subsection contains my notes on the networking subsystem.</p>
<p>Before we jump in,  notes on how packets are represented in Linux and visualizing their processing.</p>
<h3 id="n01-packet-representation-in-linux"><a class="header" href="#n01-packet-representation-in-linux">N.0.1 Packet Representation in Linux</a></h3>
<p>Packets are represented using sk_buff (socket buffer) in Linux. The struct is declared in <code>include/linux/skbuff.h</code>. I will call a packet as skb interchangeably from now on. The sk_buff struct contains two parts, the packet data and it's meta data.</p>
<p>Firstly it contains pointers to the actual data. The actual packet with Ethernet, IP, transport headers and payload that has made it's way over the network will be put in some memory that is allocated. The simplest way this is done is to allocate a contiguous memory block which will contain the whole packet. (We will see in later pages how very large packets can be created using lists of such blocks or how number of data copies can be reduced by having multiple small chunks of data.) skb-&gt;head points to the start of the this block, and skb-&gt;end points to the end of this block. The whole block need not contain meaningful data. skb-&gt;data points to the place where the packet data starts, and skb-&gt;tail points to the place where the packet data ends. This allows the packet to have some head room and tail room if the packet needs to expand. These four pointers are used to point to the actual data. They are placed at the end of the sk_buff struct. David Miller's page on <a href="http://vger.kernel.org/%7Edavem/skb_data.html">skb_data</a> describes skb data in greater detail.</p>
<p>An image from the above page: </p>
<p><img src="imgs/01_skb_layout.png" alt="skb_layout" /></p>
<p>Additionally the skb contains lots of meta data. Without checking the actual data, a fully filled skb can provide the protocol information, checksum details, it's corresponding socket, etc. The meta data is information that is extracted from the packet data or information attached to the current packet that can be used by all the layers. A few of these fields are explained in David Miller's page <a href="http://vger.kernel.org/%7Edavem/skb.html">How SKBs work</a>.</p>
<p>This is similar to how photographs are saved. One part is the actual image, the second part is meta data like it's dimensions, ISO, aperture, camera model, location information, etc. The meta data by itself is not useful but adds detail to the original data.</p>
<p>I'll add a page which describes the skb and it's fields in greater detail. TODO. </p>
<h3 id="n02-visualizing-packet-processing"><a class="header" href="#n02-visualizing-packet-processing">N.0.2 Visualizing Packet Processing</a></h3>
<p>This is not a standard way of visualizing, but I think this is the right way to visualize packet processing and cant visualize in any other way. Receiving packets is in the bottom to top direction. And transmitting packets is in the top to bottom direction. Forwarding to a different layer is left to right.
While receiving packets, drivers receive data first. The bottom most layer where the drivers stay. The drivers hand over the packet to the core network. The core networking code then passes it over to the right protocol stack(s). After the protocol stack processing is done, it enters socket layer, from where the user picks up the packet. </p>
<img src="imgs/visualize_pkt_proc.png" alt="visualize"  />
<h4 id="n021-top-half-and-bottom-half-processing"><a class="header" href="#n021-top-half-and-bottom-half-processing">N.0.2.1 Top half and bottom half processing</a></h4>
<p>The path from the driver to the socket queue is divided into two halves.</p>
<p>The top half happens first, the driver gets the raw packet and creates a skb. After an skb is created it calls functions to hand it over to the core networking code. The top half before exiting schedules the bottom half. Top half runs per packet and exits.</p>
<p>The bottom half begins picking up each packet and starts processing them. The packet is passed trough IP, UDP stacks and finally enqueues it into the socket queue. This is done for a bunch of packets. If there are packets that are still pending, the bottom half schedules itself and exits.</p>
<p>IMPORTANT:</p>
<ol>
<li>The top half is below the bottom half in my figure.</li>
<li>I can use bottom half OR softirq processing interchangeably.</li>
<li>Softirq processing done while receiving packets is also called NET_RX processing. I can use this as well. :)</li>
<li>Core network code runs in both these halves. But most of it is in softirq processing. </li>
</ol>
<p>With this, basic information we can start describing the RX and TX processing paths.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n1-setup-qemu"><a class="header" href="#n1-setup-qemu">N1 Setup Qemu</a></h1>
<p>These notes are based on the following videos:</p>
<ol>
<li><a href="https://www.youtube.com/watch?v=OdybsP9cQNA">Running an external custom kernel in Fedora 32 under QEMU: Kernel Debugging Part 1</a> I am more used to Ubuntu, so I chose it instead.</li>
<li><a href="https://www.youtube.com/watch?v=unizGCcZg3Y">GDB on the Linux Kernel</a>. </li>
</ol>
<p>The script below is the same as the one described in these videos. </p>
<p><strong>Please watch both the videos before continuing further.</strong></p>
<hr />
<p>Like described in the article on UML Setup, I like to learn by running a VM and attaching it via GDB. KVM and QEMU are the newer and well supported VM solutions. This page is a tutorial on how to launch a debug instance in QEMU and attach to it using GDB.</p>
<p>Install QEMU (check Qemu download page for distribution specific instructions). </p>
<h3 id="n11-setup--build-a-kernel-with-debug-symbols"><a class="header" href="#n11-setup--build-a-kernel-with-debug-symbols">N1.1 Setup &amp; build a kernel with debug symbols</a></h3>
<p>Clone the kernel from kernel git repo. </p>
<pre><code class="language-shell">git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git linux
cd linux 
</code></pre>
<p>Next run &quot;make menuconfig&quot; to modify a few configurations. On running the command a ncurses interface to enable/disable options will open. Use the arrow keys to move between options and 'Y' and 'N' keys to include/exclude options.
First enable CONFIG_DEBUG_KERNEL. It is located under &quot;Kernel hacking&quot; as &quot;Kernel debugging&quot;.
Next disable RANDOMIZE_MEMORY_PHYSICAL_PADDING. It is located under &quot;Processor type and features&quot; as &quot;Randomize the kernel memory sections&quot;.
After making the changes save the changes and exit the menuconfig interface. A lot of youtube videos explain the same in detail, check them if confused. To reset any changes delete the &quot;.config&quot; file and start over by running &quot;make defconfig&quot;. Finally run make.
It will take some to compile the kernel. Meanwhile move to the next step and install a VM in qemu. </p>
<pre><code>make defconfig
make menuconfig     # enable CONFIG_DEBUG_KERNEL,
                    # disable RANDOMIZE_MEMORY_PHYSICAL_PADDING

make -j1            # replace 1 with the number of CPUs that make
                    # should use to build the kernel.  
</code></pre>
<h3 id="n12-create-an-image-for-qemu"><a class="header" href="#n12-create-an-image-for-qemu">N1.2 Create an image for QEMU</a></h3>
<p>Move out of the linux directory and create an image for QEMU.</p>
<p><code>qemu-img create kernel-dev.img 20G</code> </p>
<p>Next download ubuntu's server iso image from <a href="https://ubuntu.com/download/server">here</a>. It is a ~1GB file which can be used for a Linux server. You can alternatively install the desktop version if you are more comfortable with a GUI. Move the downloaded iso file into the same directory.
Finally save the script below as start.sh.</p>
<pre><code class="language-bash">#!/bin/bash

#startup.sh

KERNEL=&quot;linux/arch/x86_64/boot/bzImage&quot;
RAM=1G
CPUS=2
DISK=&quot;kernel-dev.img&quot;

if [ $# -eq 1 ]
then
	qemu-system-x86_64 \
		-enable-kvm \
		-smp $CPUS \
		-drive file=$DISK,format=raw,index=0,media=disk \
		-m $RAM \
		-serial stdio \
		-drive file=$1,index=2,media=cdrom  ## comment to run vanilla install
		# use this option to boot using a cd iso
else
	qemu-system-x86_64 \
		-enable-kvm \
		-smp $CPUS \
		-drive file=$DISK,format=raw,index=0,media=disk \
		-m $RAM \
		-serial stdio \
		-kernel $KERNEL \
		-initrd initrd.img \
		-S -s \
		-cpu host \
		-append &quot;root=/dev/mapper/ubuntu--vg-ubuntu--lv ro nokaslr&quot; \
		-net user,hostfwd=tcp::5555-:22 -net nic \
		# use this option to run debug kernel
		# see the video 1 on how to pull the initrd.img
		# the &quot;root=/dev/ ...&quot; command needs to pulled from grub.cfg (see video 1)
fi
</code></pre>
<p>The above script when given an ISO file passes it as an CD to the QEMU instance. This way we can install ubuntu into &quot;kernel-dev.img&quot;. </p>
<p>If no arguments are provided it tries to run the OS installed on kernel-dev.img. This way we can use the script to start the VM after we have completed installing ubuntu. At this point the directory structure should look like this:</p>
<pre><code>  .
  ├── kernel-dev.img
  ├── linux
  ├── ubuntu-21.04-live-server-amd64.iso
  └── startup.sh 
</code></pre>
<p>First to install ubuntu run: (if superuser privileges needed, run with sudo) </p>
<pre><code>./startup.sh ubuntu-21.04-live-server-amd64.iso
</code></pre>
<p>Go through all the steps and install ubuntu. A lot of YouTube videos show the  complete process. Use them as a reference if necessary.</p>
<p>Once the installation is complete, comment out  the line which provides the cdrom option to boot into an vanilla ubuntu install.</p>
<pre><code>./startup.sh ubuntu-21.04-live-server-amd64.iso  #cdrom line commented
</code></pre>
<p>Now wait for the kernel compilation to complete. Then run the script without the arguments to boot into the kernel we built.</p>
<pre><code>./startup.sh
</code></pre>
<p>The boot will wait for GDB to connect. On a separate terminal run:</p>
<pre><code class="language-bash">gdb linux/vmlinux
</code></pre>
<p>Within the gdb prompt then run &quot;target remote :1234&quot; to connect to QEMU. The <code>bt</code> command should then show some stack within QEMU.
Run &quot;hbreak start_kernel&quot; to add a hardware breakpoint at start_kernel() and then run &quot;continue&quot;. The VM would then begin booting and will stop in the start_kernel function.</p>
<p>Add other hardware breakpoints (since QEMU uses hardware acceleration for Virtualization, normal SW breakpoints will not work) and start tinkering.
The network options are similar to those of UML. Thses options have been commented in the above script. </p>
<h3 id="n13-network-setup"><a class="header" href="#n13-network-setup">N1.3 Network setup</a></h3>
<p>By default the script provides an interface via which the VM can access both internet and the host machine (over ssh). This is the SLIRP networking mode. Follow the link <a href="https://wiki.qemu.org/Documentation/Networking#User_Networking_.28SLIRP.29">here</a> to read more.</p>
<p>The interface will be created. If the interface does not have an address, run dhclient on the interface so it is assigned an address. Next install an sshserver, if not installed during ubuntu installation, so we can access the guest over ssh.</p>
<pre><code class="language-bash">sudo dhclient eth0  # provide the right interface name.
sudo apt update     # needed to update apt cache.
sudo apt install openssh-server
</code></pre>
<p>Finally to login into the guest machine, run:</p>
<pre><code>ssh -p 5555 localhost 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n1-setup-uml-older"><a class="header" href="#n1-setup-uml-older">N1. Setup UML (older)</a></h1>
<p>SKIP THIS IF YOU WERE ABLE TO SETUP QEMU. This page is here only for completeness, but is not necessary to experiment with a kernel.</p>
<hr />
<p>I prefer to learn/tinker with linux using UML. UML is User mode linux, which is a simple VM. It emulates a uniprocessor linux system, and can run even on machines with very old hardware (like my laptop). Check the UML homepage for additional details. This page is just to a simple tutorial on how to build and run it. I have also added sections on how to attach it to GDB for easy debugging and a section on how to setup basic networking between multiple UMLs which you can skip in the first read. </p>
<h3 id="n01-clone-and-build-the-kernel"><a class="header" href="#n01-clone-and-build-the-kernel">N0.1 Clone and build the kernel</a></h3>
<p>Clone the kernel, and build it.
Make defconfig sets up the default kernel config. The kernel config is a set of kernel features which will either be compiled into the kernel or will be compiled as modules. The architecture for which we are configuring is the UM (user mode) architechture. While building the config, you may be prompted to choose a configuration. Press enter to choose the default configuration.
Once the configuration is done, a &quot;.config&quot; file will be populated with the chosen options.
Begin compiling the code. Based on your machine's CPU capabities, replace 1 with the number of parallel compilation jobs you want make to run. Please remain patient as the very first compilation will take some time.</p>
<pre><code class="language-bash">git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git linux
cd linux
make defconfig ARCH=um
make -j1 ARCH=um 
</code></pre>
<p>A new file &quot;linux&quot; will be created. This is the UML executable which runs as an application on the host machine. It needs a few other files and arguments to run, which will be explained in the next section.</p>
<h3 id="n011-kernel-config-optional"><a class="header" href="#n011-kernel-config-optional">N0.1.1 Kernel config [OPTIONAL]</a></h3>
<p>The kernel src includes a neat way to configure the kernel. Run make menuconfig to configure various options. A ncurses interface should start up, with the instructions provided in the top. Pressing Y includes a config and N excludes a config. After configuring the kernel, save and exit the config. The .config file will get updated with the necessary configuration.
To build the uml binary with debug symbols, edit KBUILD_HOSTCFLAGS in the Makefile. Just add a '-g' option at the end. The kernel can then be rebuilt with the new configuration.</p>
<pre><code>make menuconfig ARCH=um
make -j1 ARCH=um 
</code></pre>
<p>Makefile diff:</p>
<pre><code> HOSTCC       = gcc
 HOSTCXX      = g++
-KBUILD_HOSTCFLAGS   := -Wall -Wmissing-prototypes -Wstrict-prototypes -O2 \
+KBUILD_HOSTCFLAGS   := -Wall -Wmissing-prototypes -Wstrict-prototypes -O2 -g \
                -fomit-frame-pointer -std=gnu89 $(HOST_LFS_CFLAGS) \
                $(HOSTCFLAGS)
 KBUILD_HOSTCXXFLAGS := -O2 $(HOST_LFS_CFLAGS) $(HOSTCXXFLAGS) 
</code></pre>
<h3 id="n02-rootfs-setup"><a class="header" href="#n02-rootfs-setup">N0.2 Rootfs setup</a></h3>
<p>We have a compiled kernel but we still need a init script and other userspace  programs. We need a rootfs to emulate the disk. There are a lot of blogs  which describe how to build a rootfs. We will download a debian rootfs that is  provided by google. 
Run the following command to download the rootfs and uncompress it. On  uncompressing it a 1GiB net_test.rootfs.20150203 should be available.</p>
<pre><code>wget -nv https://dl.google.com/dl/android/net_test.rootfs.20150203.xz
unxz net_test.rootfs.20150203.xz 
</code></pre>
<p>Note: If the above download does not work, check the <a href="https://android.googlesource.com/kernel/tests/+/master/net/test/run_net_test.sh#83">Google nettest script</a> where the rootfs link can be found. Google uses    UML to run nettests on the kernels OEMs ship to check for possible bugs.<br />
We now have everything needed to run the UML.</p>
<p>.2.1 Adding files/programs to rootfs [OPTIONAL]</p>
<p>The rootfs now contains certain programs and a init script which can be used to boot into the UML. We may need to install programs for our testing or need to move files between UML and the host OS. By mounting it into a directory the rootfs contents can be accessed.</p>
<pre><code>mkdir temp
sudo mount net_test.rootfs.20150203 temp
</code></pre>
<p>Copying from/to the directory is equivalent to copying files from/to the UML. In the below example I am copying my tmux configuration files into the rootfs. When I boot into UML, I will find the config file in the home directory. (Super user privilages are needed to add/remove files from the rootfs). </p>
<pre><code>sudo cp ~/.tmux.conf temp/home/ 
</code></pre>
<p>By chroot-ing into the mounted directory, any necessary programs can be installed. On running chroot, you will able to edit the rootfs with super user privilages. I am installing tmux in the below code and then exiting the chroot shell.</p>
<pre><code>sudo chroot temp
apt-get update
apt-get install tmux
exit  
</code></pre>
<p>Once all the changes are done, unmount the rootfs.</p>
<pre><code>sudo umount temp
</code></pre>
<h4 id="0211-apt-get-is-failing"><a class="header" href="#0211-apt-get-is-failing">0.2.1.1 apt-get is failing</a></h4>
<p>Note: apt-get update may fail printing the following error:</p>
<pre><code>Err http://ftp.jp.debian.org wheezy Release.gpg
Connection failed
</code></pre>
<p>If the /etc/hosts file contains an address for a particular hostname, the  system will not do an additional DNS lookup. In this case, the address  corresponding to ftp.jp.debian.org is incorrect, causing apt-get to fail.  Run the command &quot;dig ftp.jp.debian.org&quot; in the host machine (not within chroot) to get the right address. Update the IP address to &quot;133.5.166.3&quot;.  Finally <code>/etc/hosts</code> should contain the following entries:</p>
<pre><code>127.0.0.1       localhost
::1             localhost ip6-localhost ip6-loopback
fe00::0         ip6-localnet
ff00::0         ip6-mcastprefix
ff02::1         ip6-allnodes
ff02::2         ip6-allrouters

133.5.166.3 ftp.jp.debian.org  
</code></pre>
<h4 id="0212-apt-get-is-still-failing-"><a class="header" href="#0212-apt-get-is-still-failing-">0.2.1.2 apt-get is still failing !!!</a></h4>
<p>OK, dont worry, download my rootfs from my github repo <a href="https://github.com/teja2010/teja2010.github.io/tree/master/old/extra">here</a>.</p>
<h4 id="03-take-it-for-a-spin"><a class="header" href="#03-take-it-for-a-spin">0.3 Take it for a spin</a></h4>
<p>Finally if all this works out you are ready to start a UML instance.    Just run the following command, where you provide path to rootfs as the value    against &quot;ubda&quot;, and 256MiB as the RAM. DO NOT forget the &quot;M&quot; in 256M, else    UML will try to boot with just to 256Bytes of RAM, and fail :). I usually    provide 256MiB RAM, you can go as low as 100 or 50MiB.</p>
<pre><code>./linux ubda=net_test.rootfs.20150203 mem=256M 
</code></pre>
<p>You will see the VM booting, printing dmesg, bringing up the various kernel    susbsystems.    Finally when a promt to enter the password appears, enter root as the    password. Play around with the tiny VM. When the fun ends, run &quot;halt&quot; to    shutdown UML.</p>
<h4 id="04-attach-gdb"><a class="header" href="#04-attach-gdb">0.4 Attach GDB</a></h4>
<p>It is fun to add breakpoints and view specific code in GDB. To do this,    we have to first find the process id (PID) of the main UML process.    Run the following command to find the UML pid. The output should show multiple PIDs</p>
<pre><code class="language-bash">$ ps aux | grep ubda

0 t teja     27089 12160  2  80   0 - 17629 ptrace 16:52 pts/6    00:00:18 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 S teja     27094 27089  0  80   0 - 17629 read_e 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 S teja     27095 27089  0  80   0 - 17629 poll_s 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 S teja     27096 27089  0  80   0 - 17629 poll_s 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     27097 27089  0  80   0 -  5206 ptrace 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     27288 27089  0  80   0 -  5339 ptrace 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     27352 27089  0  80   0 -  4990 ptrace 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     27353 27089  0  80   0 -  5294 ptrace 16:52 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     29405 27089  0  80   0 -  5003 ptrace 16:53 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     29408 27089  0  80   0 -  5390 ptrace 16:53 pts/6    00:00:00 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
1 t teja     29410 27089  1  80   0 -  5717 ptrace 16:53 pts/6    00:00:08 ./linux ubda=../rootfs_pool/net_test.rootfs.20150203 mem=50M
0 S teja     30278  3682  0  80   0 -  5500 pipe_w 17:05 pts/1    00:00:00 grep --color=auto ubda 
</code></pre>
<p>The third column is the process id and the fourth column is the parent PID.  In the above output PID 27089 starts and then spawns the other threads. Attach gdb to the the main parent thread, which is 27089 in the above example.</p>
<pre><code>sudo gdb -p 27089
</code></pre>
<p>GDB will read the symbols from linux and attach itself. Play around, check    the backtrace, etc. All globals are now accessable.</p>
<h3 id="05-a-private-uml-subnet"><a class="header" href="#05-a-private-uml-subnet">0.5 A private UML subnet</a></h3>
<p>In most cases we want to play around with two UMLs connected to each other    and ignorant of the rest of the world. In such cases, the simplest way is to    connect them using the mcast transport.
Make copies of the rootfs, for each UML instance. In this case have two    copies ready, and run them with one additional argument &quot;eth0&quot;. This will    add an additional eth0 interface. We set eth0 to mcast. i.e. the eth0    interfaces in both the instances are connected over mcast.</p>
<pre><code>./linux ubda=net_test.rootfs.20150203_1 mem=256M eth0=mcast
./linux ubda=net_test.rootfs.20150203_2 mem=256M eth0=mcast 
</code></pre>
<p>Assign addresses to the eth0 interfaces, and they are ready. You try pinging    the other UML. Command to assign address is:</p>
<pre><code>ip address add 192.168.1.1/24 dev eth0  
</code></pre>
<p>The full mcast readme is    <a href="http://user-mode-linux.sourceforge.net/old/text/mcast.txt">here</a>.    It contains details to create more complex mcast networks.</p>
<p>On assigning mcast to a eth device, each UML instance opens sockets which    listen to multicast traffic. If a multicast address is not assigned (like    above), all the instances listen to 239.192.168.1 . All packets are received    and then filtered out based on destination MAC address. The packets    can even be seen in packetdumps collected in the host OS.    Quoting from the above readme, &quot;It's basically like an ethernet    where all machines have promiscuous mode turned on&quot;. Bad for performance,    but very easy to setup.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n2-packet-rx-path-1--basic"><a class="header" href="#n2-packet-rx-path-1--basic">N2. Packet RX path 1 : Basic</a></h1>
<p>This page describes the code flow while receiving a packet. It begins with the packet just entering the core networking code, top half and bottom half processing, basic flow through the IP and UDP layers and finally the packet is enqueued into a socket queue.</p>
<p>Additionally hash based software packet steering across CPUs (RPS and RSS), Inter Processor Interrupts (IPI) and scheduling softirq processing is described. They can be ignored in the first read and can be revisited in later runs after gaining additional context. These sections have been marked OPTIONAL.
NAPI will be described in later pages, all NAPI APIs are ignored now.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n21-enter-the-core-top-half-processing"><a class="header" href="#n21-enter-the-core-top-half-processing">N2.1 Enter the Core, top half processing</a></h1>
<p>We assume that the driver has already picked up the packet data and has created a skb. (We will look at how drivers create skbs in the page describing NAPI). This packet needs to be sent up to the core. The kernel provides two simple function calls to do this.</p>
<pre><code>netif_rx()
netif_rx_ni() 
</code></pre>
<p>netif_rx() does two things,</p>
<ol>
<li>
<p>Enqueue the packet into a queue which contains packets that need processing.
The kernel maintains a softnet_data structure for each CPU. It is the core structure that facilitates network processing. Each softnet_data struct contains a &quot;input_pkt_queue&quot; into which packets that need to be processed will be enqueued. This queue is protected by a spinlock that is part of the queue (calls to rps_lock() and rps_unlock() are to lock/unlock the spinlock). The input_pkt_queue is of type sk_buff_head, which is used within by kernel to represent skb lists.
Before enqueuing, if the queue length is more than <code>netdev_max_backlog</code> (whose default length is 1000), the packet is dropped. This value can be modified by changing <code>/proc/sys/net/core/netdev_max_backlog</code>.
For each each packet drop sd-&gt;dropped is incremented. Certain numbers are maintained by softnet_data, I'll add a page describing the struct. TODO</p>
</li>
<li>
<p>After successfully enqueueing the packet, netif_rx schedules softirq processing if it has not already been scheduled. The next section describes how softirq is scheduled.</p>
</li>
</ol>
<p>Parts of the code have been added below. All the core networking functions are described in <code>net/core/dev.c</code>.</p>
<pre><code class="language-c">netif_rx()
{
    netif_rx_internal()
    {
        enqueue_to_backlog()
        {
            // checks on queue length
            rps_lock(sd);
            __skb_queue_tail(&amp;sd-&gt;input_pkt_queue, skb);
            rps_unlock(sd);

            ____napi_schedule(sd, &amp;sd-&gt;backlog)
            {
                // if not scheduled already schedule softirq
                __raise_softirq_irqoff(NET_RX_SOFTIRQ);
            }
        }
    }

}
</code></pre>
<p>netif_rx() and netif_rx_ni() are very similar except the later additionally begins softirq processing immediately, which will be explained in subsequent section.</p>
<p>This ends the top half processing, bottom half was scheduled, which will undertake rest of the packet processing.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n22-softirqs-softirq-scheduling-optional"><a class="header" href="#n22-softirqs-softirq-scheduling-optional">N2.2 Softirqs, Softirq Scheduling [OPTIONAL]</a></h1>
<p>One detail that I have ignored in the previous discussion is to specify which CPU the top and bottom half actually run.</p>
<p>The top half runs in the hardware interrupt (IRQ) context, which is a kernel thread which can be on any CPU. (This description is not really true, I have a separate page planned on interrupts where this will be described in more detail. Till then this way of visualizing it is not really wrong). Say it runs on CPU0, i.e. netif_rx() is called on CPU0. The packet will be enqueued onto CPU0's input_packet_queue. The kernel thread will then schedule softirq processing on CPU0 and exit. The bottom half will also run on the same CPU. This section describes how the bottom half is scheduled by the top half and how softirq begins.</p>
<p>Just Google what hard interrupts (IRQ) and soft interrupts (softirq) are for some background. Hardware interrupts (IRQs) will stop all processing. For interrupts that take very long to run, some work is done in IRQ and the rest is done in a softirq. Packet processing is one such task that takes very long to complete so NET_RX is the corresponding soft interrupt which takes care of packet processing.</p>
<p>Linux currently has the following softirqs declared in <code>include/linux/interrupt.h</code></p>
<pre><code class="language-c">enum
{
    HI_SOFTIRQ=0,
    TIMER_SOFTIRQ,
    NET_TX_SOFTIRQ,
    NET_RX_SOFTIRQ,
    BLOCK_SOFTIRQ,
    IRQ_POLL_SOFTIRQ,
    TASKLET_SOFTIRQ,
    SCHED_SOFTIRQ,
    HRTIMER_SOFTIRQ, /* Unused */
    RCU_SOFTIRQ,

    NR_SOFTIRQS

}; 
</code></pre>
<p>The names are mostly indicative of the subsystem each softirq serves. During kernel initialization, a function is registered for each of these softirqs. When softirq processing is needed, this function is called.
For example after core networking init is done, <code>net_dev_init()</code> registers <code>net_rx_action</code> and <code>net_tx_action</code> as the functions corresponding to <code>NET_RX</code> and <code>NET_TX</code>.</p>
<pre><code class="language-c">  open_softirq(NET_TX_SOFTIRQ, net_tx_action);
  open_softirq(NET_RX_SOFTIRQ, net_rx_action); 
</code></pre>
<p>A softirq is scheduled by calling <code>raise_softirq()</code>, which internally disables irqs and calls <code>__raise_softirq_irqoff()</code>. This function sets a bit corresponding to the softirq in the percpu bitmask <code>irq_stat.__softirq_pending</code>. The bitmask is used to track all pending softirqs on the CPU. This operation must be done with all interrupts are disabled on the CPU. Without interrupts disabled, the same bitmask can be overwritten by another interrupt handler, undoing the current change.</p>
<p>Grepping for <code>ksoftirqd</code> in ps, should show multiple threads, one for each CPU. These are threads spawned during init to process pending softirqs on each of the CPUs. Periodically the scheduler will allow ksoftirqd to run, and if any of the bits are set, it's registered function is called.</p>
<p>During packet RX, <code>net_rx_action()</code> is called.</p>
<p>The CFS scheduler makes sure that all threads get their fair share of CPU time. So ksoftirqd and an application thread will both get their fair share. But, during softirq processing, ksoftirqd disables all irqs and the scheduler has no way of interrupting the thread. Hence all registered functions are have checks to prevent the ksoftirqd from high-jacking the CPU for too long.
In this case, a buggy <code>net_rx_action()</code> function may be able to push packets into the socket queue but the application never will never get a chance to actually read the packets.</p>
<p>To conclude, <code>netif_rx()</code> calls <code>__raise_softirq_irqoff(NET_RX_SOFTIRQ)</code> to schedule softirq processing on the current CPU. The ksoftirqd running on the current CPU will check the bitmask, since <code>NET_RX_SOFTIRQ</code> is pending will call <code>net_rx_action()</code></p>
<h4 id="n221-run-softirq-now"><a class="header" href="#n221-run-softirq-now">N2.2.1 Run Softirq Now</a></h4>
<p>Other than softirq being scheduled by the scheduler, it is sometimes necessary to kick start processing. For example when a sudden burst of packets arrive, due to delays in softirq processing, packets might be dropped. In such cases, when a burst is detected, kick-starting packet processing is helpful. In the above example, calling <code>netif_rx_ni()</code> will kick start packet processing, in addition to enqueuing the packet .</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n23-packet-steering-rss-and-rps-optional"><a class="header" href="#n23-packet-steering-rss-and-rps-optional">N2.3 Packet Steering (RSS and RPS) [OPTIONAL]</a></h1>
<p>RSS and RPS are techniques that help with scaling packet processing across multiple CPUs. They allow distribution of packet processing across CPUs, while restricting a flow to a single CPU. i.e. each flow is assigned a CPU and flows are distributed across CPUs.</p>
<h3 id="n231-packet-flow-hash"><a class="header" href="#n231-packet-flow-hash">N2.3.1 Packet flow hash</a></h3>
<p>Firstly To identify packet flows, a hash is computed based on the following 4-tuple.
(source address, destination address, source port, destination port).
For certain protocols that do not support ports, a tuple containing just the source and destination addresses is used to compute the hash.
The hash is computed in <code>__skb_get_hash()</code>. After computing the hash, it is updated in skb-&gt;hash.
Some drivers have the hardware to offload hash computation, which is then set by the driver before passing the packet to the core networking layer.</p>
<h3 id="n232-rss-receive-side-scaling"><a class="header" href="#n232-rss-receive-side-scaling">N2.3.2 RSS: Receive Side Scaling</a></h3>
<p>RSS acheives packet steering by configuring receive queues (usually one for each CPU), and by configuring seperate interrupts for each queue and pinning the interrupts to the specific CPU. On receiving a packet, based on it's hash the packet is put in the right queue and the corresponding interrupt is raised.</p>
<h3 id="n233-rps-receive-packet-steering"><a class="header" href="#n233-rps-receive-packet-steering">N2.3.3 RPS: Receive Packet Steering</a></h3>
<p>RPS is RSS in software. While pushing the packet into the core network through <code>netif_rx()</code> or <code>netif_receive_skb()</code>, a CPU is chosen for the packet based on the <code>skb-&gt;hash</code>. The packet is then enqueued into the target CPU's input_packet_queue. Since the operation must have all interrupts disabled, a softirq cannot be directly scheduled on different core. So an Inter Processor Interrupt is used to schedule softirq processing on the other core.</p>
<p>After RSS decides to put the packet on a remote core, in the <code>rps_ipi_queued()</code> function, the target CPU's softnet struct is added to the current core's <code>sd-&gt;rps_ipi_next</code> which is a list to softnet structs for which an IPI has to be sent. During the current core's softirq processing, all the accumulated IPIs are sent to those cores by traversing the rps_ipi_next list.</p>
<p>IPIs are actually sent by scheduling a job on a remote core by  calling <code>smp_call_function_single_async()</code> during NET_RX processing.</p>
<pre><code class="language-c">netif_rx_internal(skb)
{
    cpu = get_rps_cpu(skb-&gt;dev, skb, &amp;rflow);
    enqueue_to_backlog(skb, cpu)
    {
        sd = &amp;per_cpu(softnet_data, cpu);    //get remote cpu sd
        __skb_queue_tail(&amp;sd-&gt;input_pkt_queue, skb); //enqueue
        rps_ipi_queued(sd);        //add sd to rps_ipi_next
    }
} 
</code></pre>
<p>Kernel documentation describes these methods and also provides instructions to configure them.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n24-softirq-processing-net_rx"><a class="header" href="#n24-softirq-processing-net_rx">N2.4 Softirq processing NET_RX</a></h1>
<p>Softirq processing was scheduled by the bottom half, and NET_RX begins. All of NET_RX processing is done in <code>net_rx_action()</code>. The logic is to process packets until one of the following events occurs:</p>
<ol>
<li>The packet queue is empty. In this case NET_RX softirq stops.</li>
<li>NET_RX has been running for longer than <code>netdev_budget_usecs</code>, whose default value is 2 milliseconds.</li>
<li>NET_RX has processed more than <code>netdev_budget</code> (fixed value of 300) packets. (We will revist this constraint while looking at NAPI)</li>
</ol>
<p>In cases 2 and 3, there still might be packets to process, in which case NET_RX will schedule itself before exiting, (i.e. set the NET_RX_SOFTIRQ bit before exiting), so it can process some more packets in another session. In cases 2 and 3 NET_RX processing is almost at it's limits. To indicate this <code>sd-&gt;time_squeeze</code> is incremented, so that a few parameters can be tuned. We will revisit this while discussing NAPI.</p>
<p>Softirq processing is done with elevated privilages, which can easily cause it to high-jack the complete CPU. The above constraints are to make sure that softirq processing allows the applications run. If the softirq were to high-jack the CPU, the user application would never run, and the end user would see applications not responding.</p>
<p>The actual function that dequeues packets from <code>input_pkt_queue</code> and begins processing them is <code>process_backlog()</code>. After dequeueing the packet it calls <code>__netif_receive_skb()</code> which pushes the packet up into the protocol stacks.</p>
<p>For now ignore the napi part of <code>net_rx_action()</code>, it calls <code>napi_poll()</code> which will call the registered poll function <code>n-&gt;poll()</code>. The poll function is set to process_backlog. For now believe me even if it does not make much sense. It will make sense one we look at the NAPI framework.</p>
<pre><code class="language-c">net_rx_action()
{
    unsigned long time_limit = jiffies +
                               usecs_to_jiffies(netdev_budget_usecs);
    int budget = netdev_budget;

    budget -= napi_poll(n, &amp;repoll)
    {
        work = n-&gt;poll(n, weight) // same as process_backlog
        process_backlog(n, weight)
        {
            skb_queue_splice_tail_init(&amp;sd-&gt;input_pkt_queue,
                                       &amp;sd-&gt;process_queue);
            while ((skb = __skb_dequeue(&amp;sd-&gt;process_queue)))
                __netif_receive_skb(skb);
        }
    }
    // time and budget constraints
    if (unlikely(budget &lt;= 0 ||
                 time_after_eq(jiffies, time_limit))) {
        sd-&gt;time_squeeze++;
        break;
    }
} 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n25-__netif_receive_skb_core"><a class="header" href="#n25-__netif_receive_skb_core">N2.5 <code>__netif_receive_skb_core()</code></a></h1>
<p><code>__netif_receive_skb()</code> internally calls <code>__netif_receive_skb_core()</code> for the main packet processing. <code>__netif_receive_skb_core()</code> is large function which handles multiple ways in which a packet can be processed. This section tries to cover some of them.</p>
<ol>
<li>
<p>skb timestamp:
<code>skb-&gt;tstamp</code> field is filled with the time at which the kernel began processing the packet. This information is used in various protocol stacks. One example is it's usage by AF_PACKET, which is the protocol tools like wireshark use to collect packet dumps. AF_PACKET extracts the timestamp from <code>skb-&gt;tstamp</code> and provides to userspace as part of struct tpacket_uhdr. This timestamp is the one that wireshark reports as the time at which the packet was received.</p>
</li>
<li>
<p>Increment softnet stat:
<code>sd-&gt;processed</code> is incremented, which is representative of the number of packets that were processed on a particular core. The packets might be dropped by the kernel for various reasons later, but they were processed on a particular core.</p>
</li>
<li>
<p>packet types:
At this point the packet is sent to all modules that want to process packets. The list of packet types that the kernel supports is defined in <code>include/linux/netdevice.h</code>, just above PTYPE_HASH_SIZE macro definition. Other than the ones described above, promiscuous packet types (processes packets irrespective of protocol) like AF_PACKET and custom packet_types added by various drivers and subsystems are all supported. Each of them fill up a packet_type structure and register it by calling <code>dev_add_pack()</code>. Based on the type and netdevice the struct is added to the respective packet_type list. <code>__netif_receive_skb()</code> based on the skb's protocol and netdevice traverses the particular list, delivering the packet by calling <code>packet_type-&gt;func()</code>.
All registered packet_types can be seen at <code>/proc/net/ptype</code>.</p>
</li>
</ol>
<pre><code class="language-bash">$ cat /proc/net/ptype

Type Device      Function
ALL           tpacket_rcv
0800          ip_rcv
0011          llc_rcv [llc]
0004          llc_rcv [llc]
0806          arp_rcv
86dd          ipv6_rcv 
</code></pre>
<p>The ptype lists are described below:</p>
<ol>
<li>
<p><code>ptype_all</code>: It is a global variable containing promiscuous packet_types irrespective of netdevice. Each AF_PACKET socket adds a packet_type to this list. packet_rcv() is called to pass the packet to userspace.</p>
</li>
<li>
<p><code>skb-&gt;dev-&gt;ptype_all</code>: Per netdevice list containing promiscuous packet_types specific to the netdevice. TODO: find an example.</p>
</li>
<li>
<p><code>ptype_base</code>: It is a global hash table, with key as the last 16bits of <code>packet_type-&gt;type</code> and value as a list of packet_type. For example <code>ip_packet_type</code> will be added to ptype_base[00], with <code>ptype-&gt;func</code> set to ip_rcv. While traversing, based on <code>skb-&gt;protocol</code> 's last 16bits, a list is chosen and the packet is delivered to all packet_types whose type matches skb-&gt;protocol.</p>
</li>
<li>
<p><code>skb-&gt;dev-&gt;ptype_specific</code>: Per netdevice list containing protocol specific packet types. The packet is delivered to if the skb-&gt;protocol matches ptype_type. Mellanox for example adds a <code>packet_type</code> with type set to <code>ETH_P_IP</code>, to process all UDP packets received by the driver. See <code>mlx5e_test_loopback()</code>. The name suggests some sort of loopback test. I am not really sure how. IDK.</p>
<p>One important detail is that the same packet will be sent to all applicable packet_type-s. Before delivering the skb, <code>skb-&gt;users</code> is incremented. <code>skb-&gt;users</code> is the number users that are (ONLY) reading the packet. Each module after completing necessary processing call <code>kfree_skb()</code>, which will first decrement users, and then free the skb only if skb-&gt;users hits zero. So the same skb pointer is shared by all the modules, and the last user will free the skb.</p>
</li>
<li>
<p>RX handler:
Drivers can register a rx handler, which will be called if a packet is received on the device. The <code>rx_handler</code> can return values based on which packet processing can stop or continue. If RX_HANDLER_CONSUMED is returned, the driver has completed processing the packet and <code>__netif_receive_skb_core()</code> can stop processing further. If RX_HANDLER_PASS is returned, skb processing will continue. The other values supported and ways to register/unregister a rx handler are available in <code>include/linux/netdevice.h</code> , above enum rx_handler_result.
For example if the driver wants to support a custom protocol header over IP, a rx handler can be registered which will process the outer header and return RX_HANDLER_PASS. Futher IP processing can continue when the packet is delivered to ip_packet_type. Note that the packet dumps collected will still contain the custom header. (It is actually better to return RX_HANDLER_CONSUMED and enqueue the packet by calling netif_receive_skb. This will allow the driver to run the packet through GRO offload engine and to distribute packet processing with RPS. Ignore this comment for now.)</p>
</li>
<li>
<p>Ingress Qdisc processing. We will look at it in a different page, after we have looking at Qdiscs and TX. Similar to RX handler, certain registered functions run on the packet and based on the return value, the processing can stop or continue. But unlike a RX handler, the functions to run are added from userspace.</p>
</li>
</ol>
<p>The order in which the <code>__netif_receive_skb_core()</code> delivers (if applicable) the packets is:</p>
<ul>
<li>Promiscuous packet_type</li>
<li>Ingress qdisc</li>
<li>RX handler</li>
<li>Protocol specific packet_type</li>
</ul>
<p>Finally if if none of them consume the packet, the packet is dropped and netdevice stats are incremented.</p>
<pre><code class="language-c">__netif_receive_skb_core()
{
    net_timestamp_check(!netdev_tstamp_prequeue, skb)
    {
        __net_timestamp(SKB);
    }

    __this_cpu_inc(softnet_data.processed);
    
    //Promiscuous packet_type
    list_for_each_entry_rcu(ptype, &amp;ptype_all, list) {
        if (pt_prev)
            ret = deliver_skb(skb, pt_prev, orig_dev);
        pt_prev = ptype;
    }
    list_for_each_entry_rcu(ptype, &amp;skb-&gt;dev-&gt;ptype_all, list) {
        if (pt_prev)
            ret = deliver_skb(skb, pt_prev, orig_dev);
        pt_prev = ptype;
    }
    
    //Ingress qdisc
    skb = sch_handle_ingress(skb, &amp;pt_prev, &amp;ret, orig_dev);
    
    //RX handler
    rx_handler = rcu_dereference(skb-&gt;dev-&gt;rx_handler);
    switch (rx_handler(&amp;skb)) {
    case RX_HANDLER_CONSUMED:
        ret = NET_RX_SUCCESS;
        goto out;
    case RX_HANDLER_PASS:
        break;
    default:
        BUG();
    }
    
    //Protocol specific packet_type
    deliver_ptype_list_skb(skb, &amp;pt_prev, orig_dev, type,
                           &amp;ptype_base[ntohs(type) &amp; PTYPE_HASH_MASK]);
    deliver_ptype_list_skb(skb, &amp;pt_prev, orig_dev, type,
                           &amp;skb-&gt;dev-&gt;ptype_specific);

} 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h3 id="n26-ip-layer-processing"><a class="header" href="#n26-ip-layer-processing">N2.6 IP layer Processing</a></h3>
<p>Assuming the skb is an IP packet, the skb will enter <code>ip_rcv()</code>, which then calls <code>ip_rcv_core()</code>. <code>ip_rcv_core</code> validates the IP header (checksum, checks on ip header length, etc), updates ip stats and based on the transport header set in the IP header will set <code>skb-&gt;transport_header</code>.</p>
<p>The protocol stacks maintain counts when packets enter and counts of the number of packets that were dropped. These numbers can be seen at <code>/proc/net/snmp</code>. The correspnding enum can be found at <code>include/uapi/linux/snmp.h</code>.</p>
<pre><code>ip_rcv_core()
{
    __IP_UPD_PO_STATS(net, IPSTATS_MIB_IN, skb-&gt;len);

    iph = ip_hdr(skb);
    
    if (unlikely(ip_fast_csum((u8 *)iph, iph-&gt;ihl)))
        goto csum_error;
    
    skb-&gt;transport_header = skb-&gt;network_header + iph-&gt;ihl*4;
    return skb;

csum_error:
    __IP_INC_STATS(net, IPSTATS_MIB_CSUMERRORS);
    return NULL;
}
</code></pre>
<p>ip_rcv then sends the packet through the netfilter PREROUTING chain. The netfilter subsystem allows the userspace to filter/modify/drop packets based on the packet's attributes. Tools iptables/ip6tables are used to add/remove IP/IPv6 rules. The netfilter subsystem contains 5 chains, PREROUTING, INPUT, FORWARD, OUTPUT and POSTROUTING. Each chain contains rules and corresponding actions. If a rule matches a packet, the corresponding action is taken. We will look at them in a separate page dedicated to iptables. An easy example is that it is used to act as a firewall to drop unwanted traffic.</p>
<pre><code>	                transport layer (TCP/UDP)

   ip_local_deliver_finish()
	        🠕                                   |
	      INPUT                               OUTPUT
	        |                                   🠗
	ROUTING DECISION  -----  FORWARDING  -----  +
	        🠕                                   |
	    PREROUTING                         POSTROUTING
	        |                                   🠗
	     ip_rcv()

	                     CORE NETWORKING 
</code></pre>
<p>While receiving a packet, at the end of <code>ip_rcv()</code> it enters the PREROUTING chain, at the end of which it enters <code>ip_rcv_finish()</code>. Based on the packet's ip address, a routing decision is taken if the packet should be locally consumed or if it is to forwarded to a different system. (I'll describe this in more detail in a separate page). If the packet should be locally consumed <code>ip_local_deliver()</code> is called. The packet then enters the INPUT chain, and finally comes out at <code>ip_local_deliver_finish()</code>.</p>
<p>Based on the protocol set in the IP header, the corresponding protocol handler is called. If a transport protocol is supported over IP, the corresponding handler is registered by calling inet_add_protocol().</p>
<p>Yes, this section skips a lot of content, I'll add a separate sections for IP processing, netfilter (esp. nftables) and routing.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n27-udp-layer"><a class="header" href="#n27-udp-layer">N2.7 UDP layer</a></h1>
<p>If the packet is an UDP packet, <code>udp_rcv</code> is the protocol handler called, which internally calls <code>__udp4_lib_rcv()</code>. First the packet header is validated, pseudo ip checksum is checked and then if the packet is unicast, based on the port numbers the socket is looked up, and then <code>udp_unicast_rcv_skb()</code> is called, which then calls <code>udp_queue_rcv_skb()</code>.</p>
<p><code>udp_queue_rcv_skb()</code> checks if the udp socket has a registered function to handle encapsulated packets. If the handler is found the corresponding handler is called, which processes the packet further. For example in case of XFRM encapsulation <code>xfrm4_udp_encap_rcv()</code> is registered as the handler. (XRFM short for transform, adds support to add encrypted tunnels in the kernel).</p>
<p>If no encap_rcv handler is found, full udp checksum is done and <code>__udp_queue_rcv_skb()</code> is called. Internally it calls <code>__udp_enqueue_schedule_skb()</code> which checks if the sk memory is sufficient to add the packet and then calls <code>__skb_queue_tail()</code> to enqueue the packet into <code>sk_receive_queue</code>. If the application has called the recv() system call and is waiting for the packet the process moves to __TASK_STOPPED state and the scheduler no longer schedules it. <code>sk-&gt;sk_data_ready(sk)</code> is called so that it's state is set to TASK_INTERRUPTIBLE, and the scheduler then schedules the application. On waking up, the packet is dequeued from the queue and the application recv()s the packet data. Receiving a packet and socket calls will be described in a separate page.</p>
<pre><code class="language-c">__udp4_lib_rcv()
{
    uh   = udp_hdr(skb);
    if (udp4_csum_init(skb, uh, proto)) //pseudo ip csum
        goto csum_error;

    sk = __udp4_lib_lookup_skb(skb, uh-&gt;source, uh-&gt;dest, udptable);
    if (sk) {
        return udp_unicast_rcv_skb(sk, skb, uh)
        {
            ret = udp_queue_rcv_skb(sk, skb);
                  //continued below..
        }
    }

}

udp_queue_rcv_skb(sk, skb)
{
    struct udp_sock *up = udp_sk(sk);

    encap_rcv = READ_ONCE(up-&gt;encap_rcv);
    if (encap_rcv) {
        if (udp_lib_checksum_complete(skb))
            goto csum_error;
    
        ret = encap_rcv(sk, skb);
    }
    
    udp_lib_checksum_complete(skb);
    return __udp_queue_rcv_skb(sk, skb)
    {
        rc = __udp_enqueue_schedule_skb(sk, skb)
        {
    
            rmem = atomic_read(&amp;sk-&gt;sk_rmem_alloc);
            if (rmem &gt; sk-&gt;sk_rcvbuf)
                goto drop;
    
            __skb_queue_tail(&amp;sk-&gt;sk_receive_queue, skb);
            sk-&gt;sk_data_ready(sk);
            // == sock_def_readable()
        }
    }

} 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n2-packet-tx-path-1--basic"><a class="header" href="#n2-packet-tx-path-1--basic">N2. Packet TX path 1 : Basic</a></h1>
<p>This page contains the basic code flow while transmitting a packet. It    begins with the userspace sendmsg, enters the UDP and IP stacks, finds    a route, enters core networking and finally being handed over to the driver    which pushes    it out. TX, unlike RX, can happen without a softirq being raised. The    processing happens completely in the application context. In this page I    describe packet transmission without a softirq being raised. I'll cover    how qdiscs are used in a separate page, after which NET_TX with qdiscs    will be described.</p>
<p>UDP &amp; IP stack processing and routing will be described in detail in a    separate page, this is just a basic overview.    We will end the discussion by handling over the packet to the driver. How    the driver actually transmits the packet will be described in later pages.  </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n31-32-sendmsg-from-userspace"><a class="header" href="#n31-32-sendmsg-from-userspace">N3.1-3.2 sendmsg() from userspace</a></h1>
<h3 id="31-sendmsg"><a class="header" href="#31-sendmsg">3.1 sendmsg()</a></h3>
<p>After opening a UDP socket the application gets a fd as a handle for the  underlying kernel socket. The application sends data into the socket by calling <code>send()</code> or <code>sendmsg()</code> or <code>sendto()</code>, all of which will send out UDP data.</p>
<p>​      On calling the <code>sendmsg()</code> system call, the syscall trap will save the application's process context and switch to running the kernel code. Kernel code runs in the application context, i.e. any traces that print the pid of the process will return the application's pid. If you do not know this, believe me for now, signals &amp; syscalls are explained in a  separate page. The kernel registers functions that are run for each system call. The registered function's name is <code>__do_sys_</code> + <code>syscall</code> name. In this case the function is <code>__do_sys_sendmsg()</code>, which internally      calls <code>__sys_sendmsg()</code>. The arguments passed to the call are the <code>fd</code>, the  <code>msghdr</code> struct and flags.</p>
<p>The first step is to get the kernel socket from the fd. Each fd the application  holds is a handle to a kernel socket. The socket can be for an open file, a  UDP socket, UNIX socket, etc. The socket is usually represented  with the var <code>sock</code>. <code>___sys_sendmsg</code> is called with the sock, msghdr and      flags. It simply checks if the arguments are valid, copies the msghdr      (allocated in userspace) into kernel memory and then calls <code>sock_sendmsg()</code>.</p>
<p>sock_sendmsg() checks if the application is allowed to proceed. Linux      has kernel modules like SELinux and AppArmour which audit each system      call and based on the configured rules allow or reject the system call.      If <code>security_socket_sendmsg()</code> does not return any errors, <code>sock_sendmsg_nosec()</code>      is called, which internally calls the <code>sock-&gt;ops-&gt;sendmsg()</code>.      socket ops are registered during socket creation based on the protocol family (<code>AF_INET</code>, <code>AF_INET6</code>, <code>AF_UNIX</code>) and socket type (<code>SOCK_DGRAM</code>, <code>SOCK_STREAM</code>).      Since a udp socket is a SOCK_DGRAM socket of AF_INET family the ops      registered are <code>inet_dgram_ops</code>, defined in <code>net/ipv4/af_inet.c</code>. And      <code>sock-&gt;ops-&gt;sendmsg()</code> is <code>inet_sendmsg()</code>.</p>
<pre><code class="language-c">SYSCALL_DEFINE3(sendmsg, int, fd, struct user_msghdr __user *, msg,
                unsigned int, flags)
{
    return __sys_sendmsg(fd, msg, flags) {
        sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);

        err = ___sys_sendmsg(sock, msg, &amp;msg_sys, flags) {

            //copy msg (usr mem) into msg_sys (kernel mem)
            err = copy_msghdr_from_user(msg_sys, msg, NULL, &amp;iov);
            sock_sendmsg(sock, msg_sys) {
                int err = security_socket_sendmsg();
                if(err)
                    return;

                sock_sendmsg_nosec(sock, msg_sys) {
                    sock-&gt;ops-&gt;sendmsg(sock, msg_sys);
                             //inet_sendmsg();
                }
            }
        }
    }
} 
</code></pre>
<h3 id="22-udp--ip-sendmsg"><a class="header" href="#22-udp--ip-sendmsg">2.2 UDP &amp; IP sendmsg</a></h3>
<p>At this point we will begin using the networking struct sock (different from a <code>socket</code>), represented usually with the var <code>sk</code>. Each socket will either have a valid sock or a file. In our case a <code>sock-&gt;sk</code> will contain a valid sock. We check if socket needs to be bound to a ephemeral port, and then call      <code>sk-&gt;sk_prot-&gt;sendmsg()</code>. During socket creation, the sock is added to the socket, and protocol handlers are registered to the sock. In this case,      for a UDP socket, <code>sk_prot</code> is set to <code>udp_prot</code> (defined in <code>net/ipv4/udp.c</code>).      And <code>sk_prot-&gt;sendmsg</code> is set to <code>udp_sendmsg()</code>. The arguments      have not changed, we will pass sk and msghdr.</p>
<p>​      Till this point we have not begun constructing the packet, the focus was more on socket options. <code>udp_sendmsg</code> will first extract the destination address      (usually variable <code>daddr</code>) and dest port (usually  <code>dport</code>), from  the <code>msghdr-&gt;msg_name</code>. The source port is extracted from the sock. This information is passed to find a route for the packet. The first time a      packet is sent out of a sock, the route has to be found by going through      the routing tables. This route result is saved in <code>sk-&gt;sk_dst_cache</code>,      which is used for packets that are sent later. At this point the packet's      source address is extracted from the route. All the details about the      packet's flow are saved in <code>struct flowi4</code>, which are saddr, daddr, sport,      dport, protocol, tos (type of service), sock mark, UID (user identifier),      etc. We now have all the information, the addresses, ports and certain      information to fill in the IP header with. We can begin filling in the      packet. <code>ip_make_skb()</code> will create the skb, and the skb will be sent out by calling <code>udp_send_skb()</code>.</p>
<pre><code class="language-c">int inet_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
{
    inet_autobind(sk)
    DECLARE_SOCKADDR(struct sockaddr_in *, usin, msg-&gt;msg_name);

    daddr = usin-&gt;sin_addr.s_addr; // get daddr from msghdr
    dport = usin-&gt;sin_port;

    rt = (struct rtable *)sk_dst_check(sk, 0);
    if (!rt) {
        flowi4_init_output();
        // pass daadr, dport...
        rt = ip_route_output_flow(net, fl4, sk);

        sk_dst_set(sk, dst_clone(&amp;rt-&gt;dst));
        //next time sendmsg is called, sk_dst_check() will return the rt
    }

    saddr = fl4-&gt;saddr; // route lookup complete, saddr is known

    skb = ip_make_skb(); // create skb(s)
    err = udp_send_skb(skb, fl4, &amp;cork); // send it to ip layer
} 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n33-34-alloc-skb-and-send_skb"><a class="header" href="#n33-34-alloc-skb-and-send_skb">N3.3-3.4 alloc skb and send_skb</a></h1>
<h3 id="n33-alloc-skb-fill-it-up-optional"><a class="header" href="#n33-alloc-skb-fill-it-up-optional">N3.3 Alloc skb, fill it up (OPTIONAL)</a></h3>
<p><code>ip_make_skb()</code> is called to create a skb and is provided flowi4, sk, msg ptr, msg length and route as  the arguments. This is a generic function that can be called from any tranport layer, here UDP calls it and the argument <code>tranhdrlen</code> (transport header length) is equal to sizeof an udp header. Additionally, the length field is equal to the amount of data below the      ip header, i.e. length contains payload length plus udp header length. </p>
<p>A skb queue head is inited, which      contains a list of skbs. Note that a head itself DOES NOT contain data. It      is a handle to a skb list. On init, the list is empty, with <code>sk_buff_head-&gt;next</code>      equal to <code>sk_buff_head-&gt;prev</code> equal to its own address, and <code>sk_buff_head-&gt;qlen</code>      is zero. Multiple skbs will be added to it if the msg size is greater      than the MTU, forcing IP fragmentation. For now, we will ignore ip fragmentation, so a single skb will be added to it later. </p>
<p>​      Next <code>__ip_append_data()</code> is called to fill in the queue with the skb(s).      The primary goal of <code>__ip_append_data</code> is to estimate memory necessary for  the packet(s) and accordingly create and enqueue skb(s) into the queue.  The skb needs memory necessary to accommodate:</p>
<ol>
<li>link layer headers: each device during init sets <code>dev-&gt;hh_len</code>. Hardware header length (usually represented by var <code>hh_len</code>) is the maximum space the driver will need to fill in header(s) below the network header. e.g. ethernet header is added by ethernet drivers.</li>
<li>IP and UDP headers. The function also handles the case where the packet needs IP fragmentation. In that case, additional logic to allocate memory for fragmentation headers is necessary.</li>
<li>Payload. Obviously.</li>
</ol>
<p>Additionally some extra tail space is also      provided while allocating the skb. The allocation logic is shown in the      code below. Once  the calculation is done, <code>sock_alloc_send_skb()</code> is called, which internally  calls <code>sock_alloc_send_pskb()</code> to allocate the skb. Each skb must be accounted for in the sock where it was created (TX) or in the sock where it is destined to (RX). This is to control the memory used by packets. Each sock will have restrictions on the amount of memory it can use. In this case <code>wmem</code>, the amount of data written into the socket that hasn't transmitted yet, is a constraint      while allocating data. If      wmem is full, <code>sendmsg()</code> call can get blocked (unless the socket is set to non blocking mode) till sock memory is freed. Once data is allocated, the  udp payload data is written into the skb. <code>skb-&gt;transport_header</code> and <code>skb-&gt;network_header</code> are set. IP and UDP headers haven't been filled yet, but pointers to where they have to be  filled are set. The skb is added to the skb queue and finally sock wmem is updated.</p>
<p>Next __ip_make_skb() will fill in ip header. (ignore fragmentation code for now, which will run if the queue has more than one skb). Finally it returns the created skb's pointer. </p>
<pre><code class="language-c">struct sk_buff *ip_make_skb()
{
    struct sk_buff_head queue;
    __skb_queue_head_init(&amp;queue);

    err = __ip_append_data()
    {
        hh_len = LL_RESERVED_SPACE(rt-&gt;dst.dev);

        fragheaderlen = sizeof(struct iphdr) + (opt ? opt-&gt;optlen : 0);
        // opt is NULL, fragheaderlen is equal to sizeof(struct iphdr)

        datalen = length + fraggap; //fraggap is zero
        // length = udphdr len + payload length
        fraglen = datalen + fragheaderlen;

        alloclen = fraglen;
        skb = sock_alloc_send_skb(sk,
                alloclen + hh_len + 15,
                (flags &amp; MSG_DONTWAIT), &amp;err);// ------- Step 0

        skb_reserve(skb, hh_len);  // -------------------------- Step 1
        data = skb_put(skb, fraglen + exthdrlen - pagedlen);
        // exthdrlen &amp; pagedlen are zero.  --------------------- Step 2
        skb_set_network_header(skb, exthdrlen);
        skb-&gt;transport_header = (skb-&gt;network_header +
                fragheaderlen); // --------------------- Step 3

        data += fragheaderlen + exthdrlen; // ------------------ Step 4
        // move pointer to where payload starts
        copy = datalen - transhdrlen - fraggap - pagedlen;
        // amount of payload data that needs to be copied.
        // datalen = payload len + udp header len.
        // transhdrlen = udp header len

        getfrag(from, data + transhdrlen, offset, copy, fraggap, skb);
        // getfrag is set to ip_generic_getfrag()
        {    //copy and update csum
            csum_and_copy_from_iter_full(to, len, &amp;csum, &amp;msg-&gt;msg_iter);
            skb-&gt;csum = csum_block_add(skb-&gt;csum, csum, odd);
        }

        length -= copy + transhdrlen; // copied length is subtracted

        skb-&gt;sk = sk;
        __skb_queue_tail(queue, skb);

        refcount_add(wmem_alloc_delta, &amp;sk-&gt;sk_wmem_alloc);
    }

    return __ip_make_skb(sk, fl4, &amp;queue, cork)
    {
        skb = __skb_dequeue(queue);

        iph = ip_hdr(skb);
        iph-&gt;version = 4;
        iph-&gt;ihl = 5;
        iph-&gt;tos = (cork-&gt;tos != -1) ? cork-&gt;tos : inet-&gt;tos;
        iph-&gt;frag_off = df;
        iph-&gt;ttl = ttl;
        iph-&gt;protocol = sk-&gt;sk_protocol;
        ip_copy_addrs(iph, fl4); // copy addresses from flow info
    }
} 
</code></pre>
<h4 id="n331-older-skb-allocation-logic"><a class="header" href="#n331-older-skb-allocation-logic">N3.3.1 (Older?) Skb allocation logic</a></h4>
<p>The figure below which shows how pointers in skb meta data are being updated corresponding to steps commented in the code above. These pictures are from  <a href="http://vger.kernel.org/%7Edavem/skb_data.html">davem's skb_data page</a> which describes udp packet data being filled in a skb. This logic is very different from what I have described above. It is possible that this was the allocation logic earlier. It is entirely possible I have missed something. Comments are welcome.</p>
<p><img src="N/imgs/02_skb_creation2.svg" alt="skb_creation" /></p>
<h4 id="34-udp-and-ip-send_skb"><a class="header" href="#34-udp-and-ip-send_skb">3.4 UDP and IP send_skb</a></h4>
<p>​      <code>udp_send_skb()</code> is simple, it fills in the UDP header, computes the checksum (<code>csum</code>),      and sends the skb to <code>ip_send_skb()</code>. If ip_send_skb returns an error,      SNMP value SNDBUFERRORS is incremented. And if everything goes well OUTDATAGRAMS      is incremented.</p>
<p><code>ip_send_skb()</code> calls <code>ip_local_out()</code>, which calls <code>__ip_local_out()</code> The packet      then enters the OUTPUT chain, at the end of which <code>dst_output()</code> is called.      On finding the packet's route, <code>skb_dst(dst)-&gt;output</code> is set to <code>ip_output</code>.</p>
<p>The skb then enters the POSTROUTING chain, at the end of which <code>ip_finish_output()</code>      is called. <code>ip_finish_output()</code> checks if the packet needs fragmentation (in  certain cases, the packet might have modified or the packet route might change, which may require ip fragmentation). Ignoring the fragmentation, <code>ip_finish_output2()</code> is called.</p>
<pre><code>		            transport layer (TCP/UDP)

					                        🠗       __ip_local_out()
                                          OUTPUT
		      INPUT                         🠗       dst_output()
		        |                           |
		ROUTING DECISION --- FORWARDING --- +
		        |                           |
		    PREROUTING                      🠗       ip_output()
		        |                      POSTROUTING
		                                    🠗       ip_finish_output() 

		             CORE NETWORKING 
</code></pre>
<p>​      <code>ip_finish_output2()</code> first checks if the interface the packet is being  routed out to has a corresponding neighbour entry (<code>neigh</code>). The neighbour subsystem is how the kernel manages link local connections corresponding to IP addresses. i.e. ARP to manage ipv4 addresses and NDISC for ipv6 addresses. If the next hop for an interface is not known, the corresponding messages      are triggered, and is added to the corresponding cache. The current arp      cache can be checked by printing <code>/proc/net/arp</code>. For now, the assuming      the neigh can be found, we will proceed. <code>neigh_output</code> is called, which      calls <code>neigh_hh_output()</code>. (An output function is registered in the neigh entry, which will be called if the neigh entry has expired. Ignoring this for now.)</p>
<p>​     <code>neigh_hh_output()</code> adds the hardware header necessary into the headroom. The neigh entry contains a cached hardware header, which is added while      adding a neigh entry into the neigh cache (after a successful ARP resolution      or neighbour discovery) is complete. More of this will be covered in a      separate page covering the neigh subsystem.</p>
<p>Now the skb has all necessary headers, pass it to the core networking subsystem which will let the driver send the packet out.</p>
<pre><code>static int ip_finish_output2()
{
    neigh = __ipv4_neigh_lookup_noref(dev, nexthop);
    neigh_output(neigh, skb)
    {
        hh_alen = HH_DATA_ALIGN(hh_len); //align hard header
        memcpy(skb-&gt;data - hh_alen, hh-&gt;hh_data,
                hh_alen);
    }
    __skb_push(skb, hh_len); // add the hh header
    return dev_queue_xmit(skb);
} 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n35-38-net_tx-and-driver-xmit"><a class="header" href="#n35-38-net_tx-and-driver-xmit">N3.5-3.8 NET_TX and driver xmit</a></h1>
<h3 id="n35-core-networking"><a class="header" href="#n35-core-networking">N3.5 Core networking</a></h3>
<p>​      The current section will cover the simplest case of sending out a packet.      NET_TX softirq will not be scheduled, in most cases packets will be sent      out this way.</p>
<p>​      Every real network device on creation has atleast one TX queue (var &quot;txq&quot;).      By real I mean actual physical devices: ethernet or wifi interfaces.      Virtual network devices like loopback, tun interfaces, etc are &quot;queueless&quot;,      i.e. they have a txq and a default Queue Discipline (<code>qdisc</code>), but a function is not added to      enqueue packets.</p>
<p>Run &quot;tc qdisc show dev lo&quot;, and it should show &quot;noqueue&quot; as the only queue. Other real devices have queues with  specific properties, as shown below eth0 has a <code>fq_codel</code> queue. I'll add a separate page for qdiscs, for now ignore them.</p>
<pre><code class="language-bash">$ tc qdisc show dev lo
qdisc noqueue 0: root refcnt 2

$ tc qdisc show dev eth0
qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5.0ms
interval 100.0ms memory_limit 32Mb ecn 
</code></pre>
<p>A small optional section on how loopback's xmit works is added next. For now assume our device has a queue.</p>
<p><code>__dev_queue_xmit()</code> finds the tx queue and qdisc and if a enqueue function      is present, calls <code>__dev_xmit_skb()</code> which calls the function to enqueue the      skb into the <code>qdisc</code>. At this point the skb is in the queue. We move  forward without any skb pointer held. After enqueueing the skb,      <code>__qdisc_run()</code> is called to process packets (if possible) that have been      enqueued. If no other process needs the cpu and less than 64 packets      have been processed in the current context, <code>__qdisc_run()</code> will continue      processing packets. <code>__qdisc_run</code> calls <code>qdisc_restart()</code> internally, which      dequeues skbs from the queue and calls <code>sch_direct_xmit()</code>, which calls      <code>dev_hard_start_xmit()</code> and it finally calls <code>xmit_one()</code>. <code>xmit_one()</code> will transmit one skb from the queue. </p>
<pre><code class="language-c">__dev_queue_xmit()
{
    struct netdev_queue *txq;
    struct Qdisc *q;

    txq = netdev_pick_tx(dev, skb, sb_dev);
    q = rcu_dereference_bh(txq-&gt;qdisc);
    rc = __dev_xmit_skb(skb, q, dev, txq)
    {
        rc = q-&gt;enqueue(skb, q, &amp;to_free) &amp; NET_XMIT_MASK;
        __qdisc_run(q)
        {
            //while constraints allow
            qdisc_restart(q, &amp;packets)
            {
                skb = dequeue_skb(q);
                sch_direct_xmit(skb);
            }
        }
        qdisc_run_end(q);
    }
} 
</code></pre>
<h3 id="n36-net_tx-optional"><a class="header" href="#n36-net_tx-optional">N3.6 NET_TX (OPTIONAL)</a></h3>
<p>Ironic that the article on NET_TX has this section marked as OPTIONAL. But      in simple scenarios, NET_TX softirq is almost never raised. After enqueueing      the packet,  <code>__qdisc_run()</code> cannot process packets because if one of these conditions is not met:</p>
<ol>
<li>no other process is waiting for this CPU</li>
<li>the current process has enqueued less than 64 packets.</li>
</ol>
<p>Then a NET_TX is scheduled to run. <code>__netif_schedule()</code> will raise a      NET_TX softirq if it was not already triggered on the CPU. <code>net_tx_action()</code>, the      registered function will run <code>__qdisc_run()</code> on the qdisc, after which the      flow is same as the case without a softirq raised.</p>
<p>Though we have not covered NAPI yet, <code>net_tx_action()</code> is a dual of <code>net_rx_action()</code>,  a root <code>qdisc</code> is a dual of a <code>napi</code> structure, and <code>xmit_one()</code> is a dual of <code>__netif_receive_skb()</code>, with very similar logic but in opposite directions.</p>
<h3 id="n37-driver-xmit_one"><a class="header" href="#n37-driver-xmit_one">N3.7 driver xmit_one()</a></h3>
<p>​      <code>xmit_one()</code> is the final function, which like <code>__netif_receive_skb()</code> shares      the packet with all registered promiscuous packet_types, i.e. the      global list <code>ptype_all</code> and per netdevice list <code>dev-&gt;ptype_all</code>. This is done      within <code>dev_queue_xmit_nit()</code> function. After this, <code>xmit_one</code> calls      <code>netdev_start_xmit()</code> which internally calls <code>__netdev_start_xmit()</code> to      hand over the packet to the driver by calling <code>ops-&gt;ndo_start_xmit()</code>      (ndo stands for NetDevice Ops). A <code>net_device_ops</code> struct is registered      during netdevice creation, where this function pointer is set by the driver. The driver will then send the packet out via the physical interface.</p>
<pre><code class="language-c">sch_direct_xmit() -&gt; dev_hard_start_xmit() -&gt; xmit_one()
{
    dev_queue_xmit_nit();
    //deliver skb to promisc packet types

    netdev_start_xmit()
    {
        const struct net_device_ops *ops = dev-&gt;netdev_ops;
        return ops-&gt;ndo_start_xmit(skb, dev);
    }
} 
</code></pre>
<h3 id="n38-loopback-xmit-optional"><a class="header" href="#n38-loopback-xmit-optional">N3.8 loopback xmit (OPTIONAL)</a></h3>
<p>​      Like described earlier, each device during creation registers certain      functions using the <code>net_device_ops</code> structure. Loopback registers      <code>loopback_xmit</code> as the function. On sending a packet to loopback, when      <code>ops-&gt;ndo_start_xmit</code> is called, the packet enters <code>loopback_xmit()</code>. It is      a very simple function, which increments stats and calls <code>netif_rx_ni()</code>      to begin the RX path of the packet. The end of TX coincides with the start of RX in this function. </p>
<p>​      The loopback device is described in <code>drivers/net/loopback.c</code> .</p>
<pre><code class="language-c">loopback_xmit()
{
    skb_tx_timestamp(skb);
    skb_orphan(skb);    // remove all links to the skb.
    skb-&gt;protocol = eth_type_trans(skb, dev);    // set protocol

    netif_rx(skb);    //RX!!
} 
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n4-wip-socket-programming-bts"><a class="header" href="#n4-wip-socket-programming-bts">N4. (WIP) Socket Programming BTS</a></h1>
<h3 id="this-is-a-work-in-progress-parts-of-it-may-be-incomplete-or-incorrect"><a class="header" href="#this-is-a-work-in-progress-parts-of-it-may-be-incomplete-or-incorrect">THIS IS A WORK IN PROGRESS, Parts of it may be incomplete or incorrect.</a></h3>
<hr />
<p>​    This page describes the magic that happens in the kernel behind the scenes    (BTS) while running a server and client exchanging data over TCP. A small    introduction with the basics of TCP has been added, a few optional sections    describing the internal structure of networking sockets, socket memory accounting,    time wait sockets have been added. The TCP subsystem is not described, it    requires a dedicated article, this article only mentions the basic functions    where necessary.
​    Hereon the application sending the data is the server and one receiving it    is the client. Ofcourse, both the applications can be server and client by    sending and receiving simultaneously.</p>
<h3 id="n41-basics-of-tcp"><a class="header" href="#n41-basics-of-tcp">N4.1 Basics of TCP</a></h3>
<p>​    Please skip this section if you have a fair idea how basic TCP operates.</p>
<p>​    TCP provides reliable, ordered and error-checked delivery of octets.    The server divides the data into smaller segments and assigns each of them a    sequence number and sends it out. The client sends back an acknowledgement    for each sequence received. Reliability is achieved by tracking acknowledgements    and retransmitting segments if necessary. The receiver re-assembles the packets    using the sequence numbers so the application receives it in the right order.    Finally checksum is used to verify the integrity of the data. The application    actually knows nothing of how the packets are sent and received, the kernel    works all the TCP magic in the background. (Which is why this is a Behind    The Scenes Article).</p>
<p>​    Before TCP begins transmitting the data, the server and client connect to    each other and exchange a few parameters. The server begins by binding to a    particular port. The client sends a request to the server, a SYN (short for    synchronize) packet. (A tcp packet with the SYN flag set in the header is    called a SYN packet).    The server responds with a SYN packet which also    acknowledges the packet sent by the client, i.e. SYN-ACK packet (ACK is short    for acknowledgement). The client on receiving the SYN-ACK acknowledges the    SYN sent by the server with an ACK. The exchange of these three packets    ( SYN, SYN-ACK and ACK) establishes a connection between the server and    the client. The connection on both the sides is uniquely identified by    the following four tuple:
​    (saddr, daddr, sport, dport) which are short for
​    ( source IP address, destination IP address, source    port, destination port) respectively.</p>
<p>​    Connection termination also happens with the exchange of packets between    the server and client. A FIN is sent by the initiator, to which the peer    responds with a FIN-ACK (acknowledging the initiator's FIN). The connection    closes with the initiator acknowledging the FIN-ACK.</p>
<pre><code>        SERVER                                            CLIENT

        fd1 = socket()
        listen(fd1, N)
        fd3 = accept(fd1) {
                                                        fd2 = socket()
                                                        connect(fd2) {
                                &lt;&lt;---- SYN ------
                                ---- SYN-ACK ---&gt;&gt;      }
        }                        &lt;&lt;---- ACK ------
        send(fd3, DATA)
                                ----- DATA ---&gt;&gt;
                                &lt;&lt;--- DATA -----
                                                        recv(fd2, DATA);
                                                        close(fd2);
                                &lt;&lt;---- FIN ------
        close(fd3);                ---- FIN-ACK --&gt;&gt;
                                &lt;&lt;---- ACK ------
  
</code></pre>
<h3 id="n42-socketint-domain-int-type-int-protocol"><a class="header" href="#n42-socketint-domain-int-type-int-protocol">N4.2 socket(int domain, int type, int protocol</a></h3>
<p>​    Both applications create networking sockets using the socket() system call.    The arguments are socket family, socket type and protocol type. The    <a href="http://www.man7.org/linux/man-pages/man2/socket.2.html">man page</a>    describes possible values the arguments take. AF_INET and AF_INET6 are to    create a IPv4 and IPv6 sockets respectively. Some of other options are to    create UNIX sockets for Inter process communication, NETLINK sockets for    monitoring kernel events and communicating with kernel modules,    AF_PACKET sockets to capture packets,    AF_PPPOX sockets for creating PPP tunnels, etc.</p>
<p>​    There are two major Socket types:</p>
<ol>
<li>SOCK_STREAM: used to send/recv octet streams.    For example TCP socket is a STREAM sock. Stream sockets guarantee reliable    in order delivery after a two way connection is established.    It does not preserve message boundaries. i.e. if the server    writes 40 bytes first and then 60 bytes, the client may receive all the    100 bytes in one shot, never knowing that the server wrote it in two parts.    Usually both sides agree upon a fixed boundary that is used to detect message    boundaries.    For example HTTP, which operates over TCP uses &quot;\r\n&quot; (CRLF: Carriage Return    Line Feed) as a boundary. See the  <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Message_format">wiki</a> page describing the HTTP Message format.</li>
<li>SOCK_DGRAM: Datagram are the exact opposite of SOCK_STREAM, they are    connectionless, delivery is unreliable. But message boundaries are preserved,    i.e. in the prev example, the client would receive two messages 40 and 60    bytes long (if they were not dropped on the way). An example is UDP.</li>
</ol>
<p>​    Protocol field, usually zero, is used if there are multiple protocols for a    specific (family, protocol) set. For example both SCTP and TCP both offer    SOCK_STREAM services within AF_INET family, UDP and ICMP offer DGRAM services    within the AF_INET family. TCP is the default option, so a socket call with    family AF_INET, type STREAM_SOCK and protocol set to zero will initialize a    TCP socket.    Providing IPPROTO_SCTP instead of zero will create a SCTP socket.    Explicitly setting IPPROTO_TCP will also create a TCP.</p>
<p>​    The socket() system call internally calls <code>__sys_socket()</code>, which has two parts    to it, firstly it creates a socket and a networking socket (struct sock) and    initializes them.    The second part is to create provide a fd to the application as a handle to    the socket.    <code>__sys_socket()</code> first calls    sock_create(), which internally calls <code>__sock_create()</code>. <code>__sock_create()</code> checks    the input values. It then checks if the application has permissions needed    to create the socket. For example packet sockets can be created only by    applications with admin privileges. Simple sockets like TCP &amp; UDP dont need    any special permissions. Next it allocates a socket. Based on the family,    the corresponding create function is called. All protocol families are registered    during initialization by calling sock_register(). They can be accessed via    the global variable net_families[]. In this case,    family AF_INET has the structure inet_family_ops registered, and the create    function inet_create() is called.</p>
<p>​    inet_create() searches among the registered struct proto which corresponds to    the protocol input. On finding the protocol sk_alloc() is called to create    the corresponding protocol sock, and the registered protocol init is called,    in this tcp_v4_init_sock(). The structure of the sock is described below,    an optional section. The socket is a BSD socket, while the sock is a networking    socket which handles all the protocol functionality and stores the corresponding    data. For example, in TCP the tcp sock maintains queues to track packets that    have been sent but not yet acknowledged by the peer. Once sock init is done,    control returns to __sys_socket().</p>
<p>​    __sys_socket() then assigns a fd to the socket that was created, and returns    this to the application. Any interaction with the network sock will go through    the socket. System calls will call the socket call, using the fd the    corresponding sock will be found, after which the corresponding    protocol function will be invoked. sock-&gt;sk points to the sk and sk-&gt;sk_socket    points to sock. This way knowing one, we can reach the other.</p>
<pre><code class="language-c">__sys_socket() -&gt; sock_create()
{
	sock_create() -&gt; __sock_create()
	{
		sock = sock_alloc();
		sock-&gt;type = type;
		pf = rcu_dereference(net_families[family]);
		err = pf-&gt;create(net, sock, protocol, kern);
		{
			struct inet_protosw *answer;
			struct proto *answer_prot;
			list_for_each_entry_rcu(answer, &amp;inetsw[sock-&gt;type], list) {
				//find the right protocol.
				if (protocol == answer-&gt;protocol) {
					break;
				}
			}

			sock-&gt;ops = answer-&gt;ops;	// &amp;inet_stream_ops
			answer_prot = answer-&gt;prot;	// tcp_prot
			sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot, kern);

			sock_init_data(sock, sk);
			sk-&gt;sk_protocol	   = protocol;

			sk_refcnt_debug_inc(sk);

			err = sk-&gt;sk_prot-&gt;init(sk);

		}

	}

	return sock_map_fd(sock, flags &amp; (O_CLOEXEC | O_NONBLOCK));
	// find a unused fd and bind it to the socket

}
  
</code></pre>
<p>​    The flow after calling a socket call usually follows the following pattern:</p>
<ol>
<li>syscall entry, socket lookup based on fd. </li>
<li>check if the process has the necessary security permissions</li>
<li>call the corresponding function from sock-&gt;ops</li>
<li>get sock from the socket, call the function from sk-&gt;ops</li>
</ol>
<h3 id="n43-socket-sock-inet_sock-inet_connection_sock-and-tcp_sock-optional"><a class="header" href="#n43-socket-sock-inet_sock-inet_connection_sock-and-tcp_sock-optional">N4.3 socket, sock, inet_sock, inet_connection_sock and tcp_sock (OPTIONAL)</a></h3>
<p>​    TODO:    Why two parts: socket and sock ? is a socket without sock possible ?</p>
<h3 id="n44-bindint-sockfd-const-struct-sockaddr-addr-socklen_t-addrlen"><a class="header" href="#n44-bindint-sockfd-const-struct-sockaddr-addr-socklen_t-addrlen">N4.4 bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen)</a></h3>
<p>​    TCP bind is called by server, which provides services on a well known port,    to which the client connects to. The client may also bind, but usually the    client's port is not of importance, so a bind() call is seldom made.</p>
<p>​    The usual flow, enter syscall, find the socket from fd, call the bind    function from the ops, which is inet_bind(). Then, the get the sk from    the sock, call sk-&gt;sk_prot-&gt;get_port(). In case of tcp it points to    inet_csk_get_port(). The get_port() takes two arguments, sk and port num, and    returns 0 if that port was available and was assigned to sk, and returns 1    if binding the port was not possible.</p>
<pre><code class="language-c">	int __sys_bind(fd, sockaddr, int)
	{
		sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);
		
		sock-&gt;ops-&gt;bind(sock, sockaddr, addrlen);	// inet_bind()
		{
			struct sock sk = sock-&gt;sk
			return __inet_bind(sk, uaddr, addr_len)
			{
				struct inet_sock *inet = inet_sk(sk);
				lock_sock(sk);	//lock sock

				snum = ntohs(addr-&gt;sin_port);
				if (sk-&gt;sk_prot-&gt;get_port(sk, snum))
				//	inet_csk_get_port()
				{
					err = -EADDRINUSE;
					return err;
				}
				inet-&gt;inet_sport = htons(inet-&gt;inet_num);
				// set src port

				release_sock(sk);	//unlock
			}
		}
	}
  
</code></pre>
<p>​    The TCP subsystem maintains a hash table with a list of hashbuckets corresponding    to each hash. Each bucket contains a list of sk which are bound to a port.    First, it checks if a bucket exists for the port requested. If it does not,    a new one is added and the sk is added ot the bucket. If the bucket exists,    and if the certain conditions are satisfied (see the next paragraph), the    sk is added to the bucket, and the bind is successful.</p>
<pre><code class="language-c">	/* check tables if the port is free */
	inet_csk_get_port(sk, port)
	{
		struct inet_hashinfo *hinfo = sk-&gt;sk_prot-&gt;h.hashinfo;	// hash tables
		struct inet_bind_hashbucket *head;			// a bucket
		struct inet_bind_bucket *tb = NULL;
		int ret = 1;

		if (!port) {
			head = inet_csk_find_open_port(sk, &amp;tb, &amp;port);
			// port is zero, assign a unused port
		}

		head = &amp;hinfo-&gt;bhash[inet_bhashfn(net, port,
						  hinfo-&gt;bhash_size)];
		//calc hash and find the right bucket head

		spin_lock_bh(&amp;head-&gt;lock);
		inet_bind_bucket_for_each(tb, &amp;head-&gt;chain)	//search in the bucket
			if (tb-&gt;port == port) //exact bucket found
				goto tb_found;

		// if nothing is found, this is the first sock to use the port
		tb = inet_bind_bucket_create(hinfo-&gt;bind_bucket_cachep,
					     net, head, port);

	tb_found:
		if (!hlist_empty(&amp;tb-&gt;owners)) {	// bucket has sk, i.e. port is being used
			if (sk-&gt;sk_reuse == SK_FORCE_REUSE)
				goto success;

			// see the explanation above inet_bind_bucket def by DaveM,
			// which expains the below function's checks
			if (inet_csk_bind_conflict(sk, tb, true, true))
				goto fail_unlock;
		}
	success:
		if (!inet_csk(sk)-&gt;icsk_bind_hash)
			inet_bind_hash(sk, tb, port)
			{
				inet_sk(sk)-&gt;inet_num = snum;
				sk_add_bind_node(sk, &amp;tb-&gt;owners);
				// add sk to bucket

				inet_csk(sk)-&gt;icsk_bind_hash = tb; // update pointer
			}
		ret = 0;

	fail_unlock;
		spin_unlock_bh(&amp;head-&gt;lock);
		return ret;
	}
  
</code></pre>
<p>​    Multiple sockets can be bound to a single port, both TCP and UDP use it to    allow mutliple processes to share a port. All applications that want to reuse    the port should us the reuseport socket option (SO_REUSEPORT) to allow sharing    the port. See man page socket(7), about the use of SO_REUSEPORT, where possible    use cases are also described.
​    TCP (in Linux) has a unique way of allowing multiple sockets to share a port,    this has been added as a comment in &quot;include/net/inet_hashtables.h&quot;, which  have added below. This logic is implemented in inet_csk_bind_conflict().</p>
<pre><code class="language-c">/* There are a few simple rules, which allow for local port reuse by
 * an application.  In essence:
 *
 *	1) Sockets bound to different interfaces may share a local port.
 *	   Failing that, goto test 2.
 *	2) If all sockets have sk-&gt;sk_reuse set, and none of them are in
 *	   TCP_LISTEN state, the port may be shared.
 *	   Failing that, goto test 3.
 *	3) If all sockets are bound to a specific inet_sk(sk)-&gt;rcv_saddr local
 *	   address, and none of them are the same, the port may be
 *	   shared.
 *	   Failing this, the port cannot be shared.
 *
 * The interesting point, is test #2.  This is what an FTP server does
 * all day.  To optimize this case we use a specific flag bit defined
 * below.  As we add sockets to a bind bucket list, we perform a
 * check of: (newsk-&gt;sk_reuse &amp;&amp; (newsk-&gt;sk_state != TCP_LISTEN))
 * As long as all sockets added to a bind bucket pass this test,
 * the flag bit will be set.
 * The resulting situation is that tcp_v[46]_verify_bind() can just check
 * for this flag bit, if it is set and the socket trying to bind has
 * sk-&gt;sk_reuse set, we don't even have to walk the owners list at all,
 * we return that it is ok to bind this socket to the requested local port.
 *
 * Sounds like a lot of work, but it is worth it.  In a more naive
 * implementation (ie. current FreeBSD etc.) the entire list of ports
 * must be walked for each data port opened by an ftp server.  Needless
 * to say, this does not scale at all.  With a couple thousand FTP
 * users logged onto your box, isn't it nice to know that new data
 * ports are created in O(1) time?  I thought so. ;-)	-DaveM
 */
</code></pre>
<h3 id="n45-server-listenint-sockfd-int-backlog"><a class="header" href="#n45-server-listenint-sockfd-int-backlog">N4.5 [Server] <code>listen(int sockfd, int backlog)</code></a></h3>
<p>​    After opening a socket and binding to a port, the server calls the listen()    call. It is signal to the kernel that the application is now ready to accept    connections. The kernel initializes the necessary data structures, so SYN    packets can be received. This will be explained in the accept call. The code    flow is the standard one, finally calling sk-&gt;sk_prot-&gt;listen(), the    registered function is inet_listen().</p>
<p>​    If the sock state is not TCP_LISTEN (i.e. this is the first listen() call),    sk_max_ack_backlog is set to the value supplied by the user. The sk-&gt;sk_ack_backlog    is a value that tracks the current value. The way these variables is used will    be seen before the accept call. For now the value is used to limit the number    of connections that have not been accepted by the application. The sk state    is moved to TCP_LISTEN, i.e. waiting to accept new connections. The    sk-&gt;sk_port-&gt;get_port() is called again (it was called while binding). This is    to make sure that two TCP_LISTEN sockets with the same port are not allowed    (case 2). While binding, the TCP port can be a server port or a client port.    Two client sockets reusing the port is acceptable. But a server socket and a    client socket on the same port cannot be allowed. So, though the bind() call has    not failed, because of clashing ports, the listen call can fail. The error    returned in that case is EADDRINUSE. Once the get_port call succeeds (returns 0),    inet-&gt;inet_sport is set. sk-&gt;sk_prot-&gt;hash() call is called, which similar    to get_port adds this sk into a hash table, which is maintained exclusively    for listen sockets. The function __inet_hash() is similar to inet_csk_get_port()    and hence is not explained.</p>
<pre><code class="language-c">int __sys_listen(int fd, int backlog)
{
	sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);

	if ((unsigned int)backlog &gt; somaxconn)
		backlog = somaxconn;

	err = sock-&gt;ops-&gt;listen(sock, backlog);
	// inet_listen()
	{
		struct sock *sk = sock-&gt;sk;
		old_state = sk-&gt;sk_state;

		if (old_state != TCP_LISTEN) {
			err = inet_csk_listen_start(sk, backlog);
			{
				reqsk_queue_alloc(&amp;icsk-&gt;icsk_accept_queue);

				sk-&gt;sk_max_ack_backlog = backlog;
				sk-&gt;sk_ack_backlog = 0;

				inet_sk_state_store(sk, TCP_LISTEN);
				if (!sk-&gt;sk_prot-&gt;get_port(sk, inet-&gt;inet_num)) {
					// again inet_csk_get_port(), check with tables.
					inet-&gt;inet_sport = htons(inet-&gt;inet_num);

					sk_dst_reset(sk);
					err = sk-&gt;sk_prot-&gt;hash(sk);
					//__inet_hash()

					if (likely(!err))
						return 0;
				}
			}
		}
		sk-&gt;sk_max_ack_backlog = backlog;
	}
}
  
</code></pre>
<p>​    At this point, the server is ready to accept new connections. The client has    to initiate the connection by calling connect().</p>
<h3 id="n46-client-connectint-sockfd-const-struct-sockaddr-addr-socklen_t-addrlen"><a class="header" href="#n46-client-connectint-sockfd-const-struct-sockaddr-addr-socklen_t-addrlen">N4.6 [Client] <code>connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen)</code></a></h3>
<p>​    The client calls connect() to initiate the connection, the sockaddr struct    providing the server's ip address and port. struct sockaddr is a common struct    which is passed in socket calls. The application and the kernel typecasts it    into another structure to fill/extract data. In case of IPv4 sockets,    it is set to struct sockaddr_in, which contains the IPv4 address and port.    In case of UNIX sockets, it is struct sockaddr_un.    Proper padding is added in each of them so all of them are of the same size.</p>
<p>​    The usual flow, find the sock from fd, call sock-&gt;ops-&gt;connect() which is    inet_stream_connect(). Which internally calls __inet_stream_connect() after    holding sock-&gt;sk lock. The sock state till now was SS_UNCONNECTED,    sk-&gt;sk_prot-&gt;connect() is called, which points to tcp_v4_connect(). tcp_v4_connect()    sends out a TCP SYN packet. The sock state is moved to SS_CONNECTING state.    The connect call is blocked till a SYN-ACK is received from the server in    response. Based on the sk-&gt;sk_sndtimeo value, inet_wait_for_connect() is called.    If the non-blocking option is set, the connect call will not wait for the SYN-ACK,    instead will return immediately. The application can work on something else,    while TCP sets up the connection. In the default case, it will be blocked till    a SYN-ACK returns.</p>
<pre><code class="language-c">int __sys_connect(int fd, struct sockaddr __user *uservaddr, int addrlen)
{
	sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);
	err = sock-&gt;ops-&gt;connect(sock, (struct sockaddr *)&amp;address, addrlen,
				 sock-&gt;file-&gt;f_flags);
	// inet_stream_connect()
	{
		err = __inet_stream_connect(sock, uaddr, addr_len, flags, 0);
		switch (sock-&gt;state) {
		case SS_UNCONNECTED:
			err = sk-&gt;sk_prot-&gt;connect(sk, uaddr, addr_len);
			// tcp_v4_connect()
			sock-&gt;state = SS_CONNECTING;
		}

		timeo = sock_sndtimeo(sk, flags &amp; O_NONBLOCK);
		// how long, sock has to wait for the response.

		inet_wait_for_connect(sk, timeo, writebias); //sleep for atmost timeo jiffies
		//... to be continued
  
</code></pre>
<p>​    tcp_v4_connect() sends out a SYN to the server and updates the sk state.    Sending out a packet (usually) has these three steps:</p>
<ol>
<li>Create a skb, fill up the headers.</li>
<li>Find a route to send it out</li>
<li>Call the function to hand it over to the ip layer.</li>
</ol>
<p>​     tcp_v4_connect first moves the sk state to TCP_SYN_SENT. If something else    fails, the socket is closed, state moved back to TCP_CLOSE. Next a route to    the server is found and this route is set in the sk. Once a connect call is    called, the sk will only communicate over this route, no point in trying to    route the packet each time. If an interface is brought down, all TCP connections    which use a route through the interface will get closed. After setting the route    in the sk, tcp_connect is called, which allocates the skb, and transmits it.    A timer is started to retry sending SYN packets till a SYN-ACK is sent back.</p>
<pre><code class="language-c">int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)
{
	tcp_set_state(sk, TCP_SYN_SENT);

	rt = ip_route_connect(fl4, nexthop, inet-&gt;inet_saddr,
			      RT_CONN_FLAGS(sk), sk-&gt;sk_bound_dev_if,
			      IPPROTO_TCP,
			      orig_sport, orig_dport, sk);
	sk_setup_caps(sk, &amp;rt-&gt;dst);
	{
		sk_dst_set(sk, dst);	// set the route
	}

	err = tcp_connect(sk)
	{
		buff = sk_stream_alloc_skb(sk, 0, sk-&gt;sk_allocation, true);

		tcp_rbtree_insert(&amp;sk-&gt;tcp_rtx_queue, buff);	// to retransmit later

		// send the skb
		return tcp_transmit_skb() {
			//build the tcp header
			th-&gt;source		= inet-&gt;inet_sport;
			th-&gt;dest		= inet-&gt;inet_dport;
			th-&gt;seq			= htonl(tcb-&gt;seq);
			th-&gt;ack_seq		= htonl(rcv_nxt);

			err = icsk-&gt;icsk_af_ops-&gt;queue_xmit(sk, skb, &amp;inet-&gt;cork.fl);
			//ip_queue_xmit().
		}

		/* Timer for retransmitting the SYN until a SYN-ACK is rcvd. */
		inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
					  inet_csk(sk)-&gt;icsk_rto, TCP_RTO_MAX);
		// See tcp_retransmit_timer(), which will be called on timeout.
		// it retransmits the skb returned by tcp_rtx_queue_head() on timeout.
	}
}
  
</code></pre>
<p>​    At the end of all this, the connect call is blocked, it will wake up to either    find that a    SYN-ACK was rcvd in which case the connect call succeeds, returns 0 to the user,    the application can proceed and begin sending data.    Or the connect call will wake up after multiple SYN packets    were sent and connection is closed. The connect call will return -1 and    errno is set to ETIMEDOUT.</p>
<h3 id="n47-tcp-packet-rcv"><a class="header" href="#n47-tcp-packet-rcv">N4.7 TCP packet rcv</a></h3>
<p>​    TCP's handler while receiving packets is tcp_v4_rcv(). It looks up the hashtables    maintained for bound sockets and listening sockets. If sk is not found, a reset    is sent back. If the sk-&gt;sk_state is not TCP_TIME_WAIT, further processing    is done in tcp_v4_do_rcv(). tcp_rcv_established() is called if the sk is a    established sk, for all other states tcp_rcv_state_process() is called.    We will begin with either tcp_rcv_established() or tcp_rcv_state_process()    hereon to describe the packet flow.</p>
<p>​    Another thing to keep in mind is that TCP packet processing mentioned above    happens in the NET_RX softirq context. Once the processing is done, the userspace    process, which is waiting on a system call, has to be signalled so it can    continue processing the data.</p>
<pre><code class="language-c">int tcp_v4_rcv(struct sk_buff *skb)
{
	th = (const struct tcphdr *)skb-&gt;data;

	sk = __inet_lookup_skb(&amp;tcp_hashinfo, skb, __tcp_hdrlen(th), th-&gt;source,
			       th-&gt;dest, sdif, &amp;refcounted);
	{
		sk = __inet_lookup_established(net, hashinfo, saddr, sport,
				daddr, hnum, dif, sdif);
		/* look up established sk table */

		return __inet_lookup_listener(net, hashinfo, skb, doff, saddr,
				sport, daddr, hnum, dif, sdif);
		/* look up listening sk table */
	}

	if(sk-&gt;sk_state == TCP_TIME_WAIT)
		//handle time wait. explained in the last section in this page

	tcp_v4_do_rcv(sk, skb);
	{
		if (sk-&gt;sk_state == TCP_ESTABLISHED) { /* Fast path */
			tcp_rcv_established(sk, skb);
			return 0;
		}

		/* To handle all states except TCP_ESTABLISHED &amp; TIME_WAIT */
		tcp_rcv_state_process(sk, skb);
	}
}
  
</code></pre>
<h3 id="n48-server-recv-syn"><a class="header" href="#n48-server-recv-syn">N4.8 [Server] Recv SYN</a></h3>
<p>​    On receiving a SYN, only if the sk-&gt;sk_state TCP_LISTEN, tcp_v4_conn_request()    is called. A struct tcp_request_sock is allocated and initialized. It is added    to the hash maps and a timer is started to retransmit SYN-ACKs. Finally    a SYN-ACK is sent out. The reqsk represents incoming sockets, and the number    of such req socks is limited by sk_max_ack_backlog, which is set in the    listen() call.</p>
<pre><code class="language-c">int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)
{
	//case TCP_LISTEN:
	acceptable = icsk-&gt;icsk_af_ops-&gt;conn_request(sk, skb) &gt;= 0;
	//tcp_v4_conn_request()
	{
		struct request_sock *req;
		if (sk_acceptq_is_full(sk)) {
			NET_INC_STATS(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
			goto drop;
		}
		req = inet_reqsk_alloc(rsk_ops, sk, !want_cookie);
		{
			req = reqsk_alloc();
			ireq-&gt;ireq_state = TCP_NEW_SYN_RECV;
		}

		tcp_openreq_init(req, &amp;tmp_opt, skb, sk);
		af_ops-&gt;init_req(req, sk, skb);
		// tcp_v4_init_req() : init req, copy

		inet_csk_reqsk_queue_hash_add(sk, req,
				tcp_timeout_init((struct sock *)req));
		{
			reqsk_queue_hash_req(req, timeout);
			{
				timer_setup(&amp;req-&gt;rsk_timer, reqsk_timer_handler,
						TIMER_PINNED);
				mod_timer(&amp;req-&gt;rsk_timer, jiffies + timeout);

				inet_ehash_insert(req_to_sk(req), NULL);
			}

			inet_csk_reqsk_queue_added(sk);
			// increment icsk_accept_queue length
		}

		af_ops-&gt;send_synack(sk, dst, &amp;fl, req, &amp;foc,
				    !want_cookie ? TCP_SYNACK_NORMAL :
						   TCP_SYNACK_COOKIE);
		{
			skb = tcp_make_synack(sk, dst, req, foc, synack_type);
			err = ip_build_and_send_pkt(skb, sk, ireq-&gt;ir_loc_addr,
					ireq-&gt;ir_rmt_addr,
					rcu_dereference(ireq-&gt;ireq_opt));
		}

	}
}
  
</code></pre>
<h3 id="n49-client-recv-syn-ack"><a class="header" href="#n49-client-recv-syn-ack">N4.9 [Client] Recv SYN-ACK</a></h3>
<p>​    Fairly straight forward, the sock is found, tcp header data added into the    sock. The sock is moved to the TCP_ESTABLISHED state and the process waiting    in the connect() call.</p>
<pre><code>int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)
{
	//case TCP_SYN_SENT:
	queued = tcp_rcv_synsent_state_process(sk, skb, th);
	{
		tp-&gt;rcv_nxt = TCP_SKB_CB(skb)-&gt;seq + 1;
		tp-&gt;rcv_wup = TCP_SKB_CB(skb)-&gt;seq + 1;
		tcp_finish_connect(sk, skb);
		{
			tcp_set_state(sk, TCP_ESTABLISHED);

			if (!sock_flag(sk, SOCK_DEAD)) {
				sk-&gt;sk_state_change(sk); //sock_def_wakeup()
				{
					wake_up_interruptible_all(&amp;wq-&gt;wait);
					// wakeup the process waiting on connect()
				}
			}
		}
		tcp_send_ack(sk);
		return -1;
	}
}
  
</code></pre>
<h3 id="m410-client-connect-continued"><a class="header" href="#m410-client-connect-continued">M4.10 [Client] connect() [continued]</a></h3>
<p>​    The process waiting on connect system call wakes up, and if the sock state    is not TCP_CLOSE, the connect was successful. The socket state is moved    to SS_CONNECTED.</p>
<pre><code>		inet_wait_for_connect(sk, timeo, writebias);
		
		/* Connection was closed by RST, timeout, ICMP error
		 * or another process disconnected us.
		 */
		if (sk-&gt;sk_state == TCP_CLOSE)
			goto sock_error;

		sock-&gt;state = SS_CONNECTED;
	} // inet_stream_connect
} // __sys_connect
  
</code></pre>
<h3 id="n411-server-recv-ack"><a class="header" href="#n411-server-recv-ack">N4.11 [Server] Recv ACK</a></h3>
<p>On receiving the ACK in response to the sent SYN-ACK, initial socket lookup  will return the request_sock created earlier which is in the TCP_NEW_SYN_RECV  state. This sock is not a full blown sock which can handle a TCP connection.  The kernel now creates another tcp_sock which will replace this sock.</p>
<p>The syn_recv_sock() function registered within inet connection ops is called,  which is set to tcp_v4_syn_recv_sock(). Firstly if the accept queue is full,  the new packet is dropped. Next a new sock is created in inet_csk_clone_lock(),  data from inet request sock is copied into newsk and its state is set to  TCP_SYN_RECV. Next tcp specific data is copied from the listen socket into the  new sock. __inet_inherit_port() edits the hashbuckets to make sure that any  socket lookups will fetch the newsk and not reqsk. Finally the reqsk is added  into the accept queue, and req-&gt;sk points to the newly created sock.</p>
<p>Finally the skb (ACK) is processed holding the new sock. The new sock is called  the child sock as well. Since the new sock 's state is in TCP_SYN_RECV and a  valid ACK was received, the child sock moves to TCP_ESTABLISHED state.</p>
<p>Since the process waits on accept() call on the listen fd to accept new  connections, the process is woken up by calling sk_data_ready().</p>
<pre><code class="language-c">int tcp_v4_rcv(struct sk_buff *skb)
{
	sk = __inet_lookup_skb(&amp;tcp_hashinfo, skb, __tcp_hdrlen(th), th-&gt;source,
				   th-&gt;dest, sdif, &amp;refcounted);
	if (sk-&gt;sk_state == TCP_NEW_SYN_RECV) {
		struct request_sock *req = inet_reqsk(sk);
		struct sock *nsk;

		sk = req-&gt;rsk_listener;
		nsk = tcp_check_req(sk, skb, req, false, &amp;req_stolen);
		{
			child = inet_csk(sk)-&gt;icsk_af_ops-&gt;syn_recv_sock(sk, skb, req);
			//tcp_v4_syn_recv_sock()
			{
				if (sk_acceptq_is_full(sk))
					goto exit_overflow;

				newsk = tcp_create_openreq_child(sk, req, skb);
				{
					struct sock *newsk = inet_csk_clone_lock(sk, req, GFP_ATOMIC);
					{
						inet_sk_set_state(newsk, TCP_SYN_RECV);
						// copy data from inet_rsk(req) into newsk
					}
					// copy data from req into newsk

					newtp = tcp_sk(newsk);
					oldtp = tcp_sk(sk);
					//init newtp ; copy data from oldtp into newtp

					return newsk;
				}

				__inet_inherit_port(sk, newsk);
				return newsk;
			}
			return inet_csk_complete_hashdance(sk, child, req, own_req);
			{
				inet_csk_reqsk_queue_drop(sk, req);
				reqsk_queue_removed(&amp;inet_csk(sk)-&gt;icsk_accept_queue, req);
				inet_csk_reqsk_queue_add(sk, req, child)
				{
					struct request_sock_queue *queue = &amp;inet_csk(sk)-&gt;icsk_accept_queue;
					req-&gt;sk = child;
					queue-&gt;rskq_accept_tail-&gt;dl_next = req;
				}
			}
		}

		tcp_child_process(sk, nsk, skb);
		{
			int state = child-&gt;sk_state;
			ret = tcp_rcv_state_process(child, skb);
			{
				switch (child-&gt;sk_state) {
					case TCP_SYN_RECV:
						tcp_set_state(child, TCP_ESTABLISHED);
				}
			}
			/* Wakeup parent, send SIGIO */
			if (state == TCP_SYN_RECV &amp;&amp; child-&gt;sk_state != state)
				parent-&gt;sk_data_ready(parent);
		}
	}
}
  
</code></pre>
<h3 id="n412-server-accept"><a class="header" href="#n412-server-accept">N4.12 [Server] accept()</a></h3>
<p>The accept call takes the listenfd and returns a fd for the established  connection. This fd will be used to transfer data, while the listen fd wil  continue accepting connections.</p>
<p>A socket is allocated and an unused fd is assigned to it. Next inet_accept  is called, which calls inet_csk_accept. Here the icsk_accept_queue is checked,  if empty the process sleeps waiting for a connection. Once a connection is  established, an entry is dequeued  from the icsk_accept_queue. This  request sock req points to the full tcp sock which is returned. Also reqsk_put()  is called, so if the refcount is zero the socket will be freed.</p>
<p>The new sock is connected to the socket allocated earlier and the socket is  moved to SS_CONNECTED state. Now the user can send/recv data using this fd.</p>
<pre><code class="language-c">int __sys_accept4(int fd, struct sockaddr __user *upeer_sockaddr,
		  int __user *upeer_addrlen, int flags)
{
	sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);

	newsock = sock_alloc();
	newsock-&gt;type = sock-&gt;type;
	newsock-&gt;ops = sock-&gt;ops;

	newfd = get_unused_fd_flags(flags);
	newfile = sock_alloc_file(newsock);

	err = sock-&gt;ops-&gt;accept(sock, newsock, sock-&gt;file-&gt;f_flags, false);
	//inet_accept()
	{
		struct sock *sk1 = sock-&gt;sk;
		int err = -EINVAL;
		struct sock *sk2 = sk1-&gt;sk_prot-&gt;accept(sk1, flags, &amp;err, kern);
		//inet_csk_accept()
		{
			struct request_sock_queue *queue = &amp;icsk-&gt;icsk_accept_queue;
			struct request_sock *req;

			if (reqsk_queue_empty(queue)) {
				long timeo = sock_rcvtimeo(sk, flags &amp; O_NONBLOCK);
				inet_csk_wait_for_connect(sk, timeo);
				{
					prepare_to_wait_exclusive(sk_sleep(sk), &amp;wait,
							TASK_INTERRUPTIBLE);
					// waits till sk_data_ready() is called
				}
			}
			req = reqsk_queue_remove(queue, sk);
			{
				struct request_sock_queue *queue = &amp;inet_csk(sk)-&gt;icsk_accept_queue;
				req = queue-&gt;rskq_accept_head;
			}
			newsk = req-&gt;sk;
			reqsk_put(req);

			return newsk;
		}

		sock_graft(sk2, newsock);
		newsock-&gt;state = SS_CONNECTED;
	}

	fd_install(newfd, newfile);
	return newfd;
}
  
</code></pre>
<h3 id="n413-send-and-recv"><a class="header" href="#n413-send-and-recv">N4.13 send() and recv()</a></h3>
<p>Sending a message is similar to the way it is described in  <a href="N/./3_Packet_TX_Basic.html">Packet TX path 1 : Basic</a>. Just pasting the  call flow below.</p>
<pre><code>	__sys_sendmsg(int fd, struct user_msghdr __user *msg)
	 ___sys_sendmsg(sock, msg, &amp;msg_sys, flags, NULL, 0);
	sock_sendmsg(sock, msg_sys);
	int sock_sendmsg_nosec(sock, msg)
	inet_sendmsg(sock, msg, size);
	tcp_sendmsg(sk, msg, size);
	tcp_sendmsg_locked(sk, msg, size);
	tcp_push_one(sk, mss_now);
	tcp_write_xmit(sk, mss_now, TCP_NAGLE_PUSH, 1, sk-&gt;sk_allocation);
	tcp_transmit_skb(sk, skb, 1, gfp);
	__tcp_transmit_skb(sk, skb, clone_it, gfp_mask, tcp_sk(sk)-&gt;rcv_nxt);
	icsk-&gt;icsk_af_ops-&gt;queue_xmit(sk, skb, &amp;inet-&gt;cork.fl);
  
</code></pre>
<p>On receiving a packet, similar to the description in  <a href="N/2_Packet_RX_Basic.html">Packet RX path 1 : Basic</a>, the packet is added  to the socket queue and the kernel wakes up the process, if the process is  waiting on the recv() system call.  Just pasting the flow of packet till sock enqueue below.</p>
<pre><code>	void tcp_rcv_established(struct sock *sk, struct sk_buff *skb)
	tcp_queue_rcv(sk, skb, tcp_header_len, &amp;fragstolen);
	{
		__skb_queue_tail(&amp;sk-&gt;sk_receive_queue, skb);
		tcp_data_ready(sk);	// wake up the process
	}
  
</code></pre>
<p>The recv() system call is simple, if a packet is available in the sk_receive_queue  the data is copied into the buffer else the process sleeps waiting for a packet.  The tcp subsystem makes sure that the packets are added in the right order using  sequence numbers.</p>
<pre><code>	long __sys_recvmsg(int fd, struct user_msghdr __user *msg, unsigned int flags)
	{
		sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);
		err = ___sys_recvmsg(sock, msg, &amp;msg_sys, flags, 0);
		sock_recvmsg_nosec(sock, msg_sys, flags);
		{
			return sock-&gt;ops-&gt;recvmsg(sock, msg, msg_data_left(msg), flags);
			//inet_recvmsg()
			{
				err = sk-&gt;sk_prot-&gt;recvmsg(sk, msg, size, flags &amp; MSG_DONTWAIT,
							   flags &amp; ~MSG_DONTWAIT, &amp;addr_len);
				//tcp_recvmsg()
				{
					timeo = sock_rcvtimeo(sk, nonblock);
					sk_wait_data(sk, &amp;timeo, last);

					skb_copy_datagram_msg(skb, offset, msg, used);
					//copy data into msg
					sk_eat_skb(sk, skb);
				}
			}
		}
	}
  
</code></pre>
<h3 id="n414-close-or-the-process-died-ungraceful-shutdown"><a class="header" href="#n414-close-or-the-process-died-ungraceful-shutdown">N4.14 close() or the process died: Ungraceful shutdown</a></h3>
<p>If a process wants to abort the connection or in case the process crashes or  is killed without closing it's open tcp socket, a RST is sent to the peer closing  the connection. We will describe the close() system call below.</p>
<p>On calling close() on a established tcp_sock, all packets that are waiting in  the receive queue are dropped, all packets in send queue are pushed out and  a RST is sent to close the TCP connection. The sock is moved to TCP_CLOSE state  and sock is freed.</p>
<pre><code class="language-c">	SYSCALL_DEFINE1(close, unsigned int, fd)
	{
		int retval = __close_fd(current-&gt;files, fd);
		{
			return filp_close(file, files);
			{
				fput(filp);
				{
					schedule_delayed_work(&amp;delayed_fput_work, 1);
					//schedule delayed_fput()
				}
			}

			__put_unused_fd(files, fd);	// fd can be reused
		}
	}

	static void delayed_fput(struct work_struct *unused)
	{
		struct file *f, *t;
		__fput(f);
		{
			file-&gt;f_op-&gt;release(inode, file);
			//inet_release()
			{
				struct sock *sk = sock-&gt;sk;
				sock-&gt;sk = NULL;
				sk-&gt;sk_prot-&gt;close(sk, timeout);
				{
					if (sk-&gt;sk_state == TCP_LISTEN) {
						tcp_set_state(sk, TCP_CLOSE);

						/* Special case. */
						inet_csk_listen_stop(sk);

						goto adjudge_to_death;
					}
					while ((skb = __skb_dequeue(&amp;sk-&gt;sk_receive_queue)) != NULL) {
						//dequeue and free all skbs
						__kfree_skb(skb);
					}
					tcp_set_state(sk, TCP_CLOSE);
					tcp_send_active_reset(sk, sk-&gt;sk_allocation);

				adjudge_to_death:
					state = sk-&gt;sk_state;
					sock_hold(sk);
					sock_orphan(sk);
					sock_put(sk);
				}

			}
		}
	}
  
</code></pre>
<p>One minor thing to note is that if the process reads all data enqueued in the  receive queue and then calls close(), the kernel will close the connection  gracefully by sending out a FIN, as described in the next section.</p>
<h3 id="n415-shutdown"><a class="header" href="#n415-shutdown">N4.15 shutdown()</a></h3>
<p>Shutdown is the graceful way of closing, where the initiator sends out a FIN  and the peer acknowledges it by sending a FIN-ACK, and finally the initiator  sends a ACK. Similar to the way connection establishment happens, using FIN  instead of SYN. Both peers close their sockets.</p>
<pre><code class="language-c">	int __sys_shutdown(int fd, int how)
	{
		sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);
		err = sock-&gt;ops-&gt;shutdown(sock, how);
		//inet_shutdown()
		{
			sk-&gt;sk_prot-&gt;shutdown(sk, how);
			//tcp_shutdown()
			{
				if (tcp_close_state(sk))
					tcp_send_fin(sk);
			}
		}
	}
  
</code></pre>
<p>The initiator moves to the TCP_FIN_WAIT1 state and on receiving a FIN-ACK  eventually closes the socket.
The socket is eventually reused for another connection. A delayed FIN, that  was meant for the previous connection may arrive causing the connection to  close. To prevent this, before closing the TCP sockets moves to a TIME WAIT  state, accepting any packets from the peer. After a sufficiently long time  the socket is closed.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n5-wip-netfilter-internals"><a class="header" href="#n5-wip-netfilter-internals">N5. (WIP) Netfilter Internals</a></h1>
<p>Links:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=cODU94yVxDs">intro to nftables</a></li>
<li><a href="https://wiki.nftables.org/wiki-nftables/index.php/Portal:DeveloperDocs">netfilter developer docs</a>
<ul>
<li><a href="https://wiki.nftables.org/wiki-nftables/index.php/Portal:DeveloperDocs/nftables_internals">nftables internals</a> </li>
<li><a href="https://wiki.nftables.org/wiki-nftables/index.php/Portal:DeveloperDocs/nftables_internals">sets internals</a></li>
</ul>
</li>
</ul>
<hr />
<p>These notes will mostly cover the nftable portion. The hooks into a netfilter are the same, but the way rules are created and composed is different for iptables.</p>
<p>We will start with a simple rule to count packets and see how this rule is actually implemented within netfilter. Next we will slowly improve and add parts to the rule to learn other features.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n51-rule-matching"><a class="header" href="#n51-rule-matching">N5.1 Rule Matching</a></h1>
<h3 id="n510-setup-table-chain-and-a-rule"><a class="header" href="#n510-setup-table-chain-and-a-rule">N5.1.0 Setup table, chain and a rule</a></h3>
<p>Let us first setup a simple table, a chain and rule that counts all packets whose source address is <code>127.0.0.1</code></p>
<p>For our current exploration, lets add a simple rule which counts packets from 127.0.0.9</p>
<pre><code class="language-sh">$ nft add table ip T  # a table called T
$ nft add chain T C { type filter hook prerouting priority 0\; }  # a chain C
$ nft add rule T C ip saddr 127.0.0.9 counter
</code></pre>
<p>The above chain has been added in the prerouting hook, i.e. it will run before the kernel makes a rounting decision. A kernel based on the routing table, will decide if the packet has to forwarded out of an network interface or will be consumed locally by an application.</p>
<p>Next to check the ruleset:</p>
<pre><code class="language-sh">$ nft list ruleset 

table ip T {
        chain C {
                type filter hook prerouting priority filter; policy accept;
                ip daddr 127.0.0.9 counter packets 4 bytes 336
        }
}
</code></pre>
<p>Run pings to that address, and we can see the counter increase.</p>
<pre><code class="language-sh">$ ping 127.0.0.9
</code></pre>
<h3 id="n511-rule-matching-in-net_rxnet_tx"><a class="header" href="#n511-rule-matching-in-net_rxnet_tx">N5.1.1 Rule matching in NET_RX/NET_TX</a></h3>
<p>Like discussed in the RX,TX path articles, netfilter processing happens in the softirq context. The pre-routing hook is hit in <code>ip_rcv</code></p>
<pre><code class="language-c">int ip_rcv(struct sk_buff *skb, struct net_device *dev,
           struct packet_type *pt,
	       struct net_device *orig_dev)
{
	struct net *net = dev_net(dev);

	skb = ip_rcv_core(skb, net);
	if (skb == NULL)
		return NET_RX_DROP;

	return NF_HOOK(NFPROTO_IPV4, NF_INET_PRE_ROUTING,
		       net, NULL, skb, dev, NULL,
		       ip_rcv_finish);
}

</code></pre>
<p>On entering NF_HOOK it internally calls calls nf_hook. If the nf filters return a verdict of accept, the packet is passed into the okfn (<code>ip_rcv_finish</code> in  this case ).  Take a look at all the data that is passed into the netfilter  hooks.</p>
<pre><code class="language-c">static inline int
NF_HOOK(uint8_t pf,              //protocol family (IP in our case)
		 unsigned int hook,      //PREROUTING
		 struct net *net,        //network namespace (net_init)
		 struct sock *sk,        //will be set if sock lookup happens early on
	     struct sk_buff *skb,    //the packet
	     struct net_device *in,  //source device
	     struct net_device *out, //destination device (if routing is complete)
	     int (*okfn)(struct net *, struct sock *, struct sk_buff *))
	                             //func to run on ACCEPT
{
	int ret = nf_hook(pf, hook, net, sk, skb, in, out, okfn);
    if (ret == 1) 
		ret = okfn(net, sk, skb);
	return ret;
}
</code></pre>
<p><code>nf_hook</code> then based on the hook and protocol family which called NF_HOOK, chooses a list of <code>nf_hook_entries</code>. This list is then traversed in <code>nf_hook_slow</code>.</p>
<pre><code class="language-c">static inline int
nf_hook(u_int8_t pf,
        unsigned int hook, struct net *net,
        struct sock *sk, struct sk_buff *skb,
        struct net_device *indev, struct net_device *outdev,
        int (*okfn)(struct net *, struct sock *, struct sk_buff *))
{
	struct nf_hook_entries *hook_head = NULL;
	
	rcu_read_lock();
	switch (pf) {
	case NFPROTO_IPV4:
		hook_head = rcu_dereference(net-&gt;nf.hooks_ipv4[hook]);
		break;
		// ... other protocols //
		
		default:
		WARN_ON_ONCE(1);
		break;
	}
	
	if (hook_head) {
		struct nf_hook_state state;
		nf_hook_state_init(&amp;state, hook, pf, indev, outdev,
				   sk, net, okfn);
		ret = nf_hook_slow(skb, &amp;state, hook_head, 0);
	}
	rcu_read_unlock();

	return ret;
}
</code></pre>
<p><code>nf_hook_slow</code> is the actual function that runs each of the hook_entry functions. If any of the hook functions return a terminating verdict (<code>NF_ACCEPT</code> or <code>NF_DROP</code>),  the loop is broken and the verdict is returned.</p>
<pre><code class="language-c">int nf_hook_slow(struct sk_buff *skb, struct nf_hook_state *state,
		 const struct nf_hook_entries *e,
         unsigned int s)
{
	unsigned int verdict;
	int ret;

	for (; s &lt; e-&gt;num_hook_entries; s++) {
		verdict = nf_hook_entry_hookfn(&amp;e-&gt;hooks[s], skb, state);
		switch (verdict &amp; NF_VERDICT_MASK) {
		case NF_ACCEPT:
			break;
		case NF_DROP:
			kfree_skb(skb);
			ret = NF_DROP_GETERR(verdict);
			if (ret == 0)
				ret = -EPERM;
			return ret;
		// ... other verdicts ///
		}
	}

	return 1;
}
</code></pre>
<p>The <code>hook_entries</code> are added in <code>nf_register_net_hook</code> , which takes a <code>struct nf_hook_ops</code> which is called while adding a rule.  In our case, for ipv4, <code>nft_chain_filter_ipv4_init</code> registers <code>nft_do_chain_ipv4</code> as the hook function.</p>
<p><code>nft_do_chain_ipv4</code> simply sets pktinfo from the skb and calls <code>nft_do_chain</code>.</p>
<p>All chains finally enter <code>nft_do_chain</code>  which matches the packet against rules. How rules are translated into register operations will discussed in a later article. But, for now <code>nft_do_chain</code> is the actual function that matches rules against packets and returns a verdict</p>
<p>The overall stack at this point looks like:</p>
<pre><code class="language-c">(gdb) hbreak nft_do_chain
Hardware assisted breakpoint 3 at 0xffffffff83399250: file net/netfilter/nf_tables_core.c, line 159.

(gdb) bt
#0  nft_do_chain ()
#1  nft_do_chain_ipv4 () 
#2  nf_hook_entry_hookfn ()
#3  nf_hook_slow ()
#4  nf_hook_slow_list ()
#5  NF_HOOK_LIST (pf=2 '\002',...
				  okfn=0xffffffff83487250 &lt;ip_rcv_finish&gt;, ...)
#6  ip_sublist_rcv ()
#7  ip_list_rcv ()
#8  __netif_receive_skb_list_ptype ()
#9  __netif_receive_skb_list_core ()
#10  __netif_receive_skb_list ()
#11 netif_receive_skb_list_internal ()
    ... napi poll ...
#18 net_rx_action () at net/core/dev.c:7201
#19 __do_softirq () at kernel/softirq.c:558
#20 do_softirq () at kernel/softirq.c:459
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n52-rule-deconstruction"><a class="header" href="#n52-rule-deconstruction">N5.2 Rule deconstruction</a></h1>
<p>This article looks at how each rule is constructed and how a VM is emulated within netfilter to enforce the rules. Running <code>nft -d netlink</code>  shows the instructions which the rule is converted into:</p>
<pre><code class="language-sh">$ nft -d netlink add rule T C ip daddr 127.0.0.9 counter
ip 
  [ payload load 4b @ network header + 16 =&gt; reg 1 ]
  [ cmp eq reg 1 0x0900007f ]
  [ counter pkts 0 bytes 0 ]
</code></pre>
<p>Going through each instruction expression:</p>
<p><code>[ payload load 4b @ network header + 16 =&gt; reg 1 ]</code>  read 4 bytes from the network header at an offset of 16 and store it in register 1 ,</p>
<p><code>[ cmp eq reg 1 0x0900007f ]</code> compare register 1 with <code>0x0900007f</code> ( <code>127.0.0.9</code> in network order) ,</p>
<p><code>[ counter pkts 0 bytes 0 ]</code>  increment counter.</p>
<h3 id="n521-nft_rule"><a class="header" href="#n521-nft_rule">N5.2.1 nft_rule</a></h3>
<p><code>struct nft_rule</code> is constructed for each rule. The expressions described  above are added to it</p>
<pre><code class="language-c">struct nft_rule {
	struct list_head        list;    // to add rules into a list
	u64                     handle:42,       // handle to refer to the rule (see nft -a list ruleset)
							genmask:2,       // generation
							dlen:12,         // length of data
							udata:1;         
	unsigned char           data[]           // register data
};
</code></pre>
<p>The expressions are stored in <code>nft_rule-&gt;data</code>. Each expression is made up of a pointer to the ops structure and register specific data.</p>
<pre><code class="language-c">(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[0] )-&gt;ops
$23 = (const struct nft_expr_ops *) 0xffffffff84683300 &lt;nft_payload_fast_ops&gt;
(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[0] )-&gt;ops-&gt;size
$24 = 16
(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[16] )-&gt;ops      # 0 + 16
$25 = (const struct nft_expr_ops *) 0xffffffff846824a0 &lt;nft_cmp_fast_ops&gt;
(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[16] )-&gt;ops-&gt;size
$26 = 24
(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[40] )-&gt;ops      # 16 + 24
$27 = (const struct nft_expr_ops *) 0xffffffff846881a0 &lt;nft_counter_ops&gt;
(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[40] )-&gt;ops-&gt;size
$28 = 16
(gdb) p rule-&gt;dlen                                  # 56 = 16 + 24 + 16 
$30 = 56
</code></pre>
<p>The first expression is to load payload into a register and the expression is stored in a <code>struct nft_payload</code> .</p>
<pre><code class="language-c">(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[0] )-&gt;ops 
$43 = (const struct nft_expr_ops *) 0xffffffff84683300 &lt;nft_payload_fast_ops&gt;
(gdb) p *(struct nft_payload*)((struct nft_expr *)&amp;rule-&gt;data[0] )-&gt;data
$44 = {base = NFT_PAYLOAD_NETWORK_HEADER,  // base header
       offset = 16 '\020',         // offset from header start
       dreg = 4 '\004',            // dest register
       len = 4 '\004',             // length of the expression (4 x u8)
      }

// [ payload load 4b @ network header + 16 =&gt; reg 1 ]
</code></pre>
<p>The eval function <code>nft_payload_eval</code> maps base to a header, reads the header offset and then calls <code>skb_copy_bits</code> to read bits into a register.</p>
<p>The next expression is to compare it to <code>127.0.0.9</code></p>
<pre><code class="language-c">(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[16] )-&gt;ops 
$48 = (const struct nft_expr_ops *) 0xffffffff846824a0 &lt;nft_cmp_fast_ops&gt;
(gdb) p/x *(struct nft_cmp_fast_expr*)((struct nft_expr *)&amp;rule-&gt;data[16] )-&gt;data
$49 = {data = 0x900007f,       // 127.0.0.9
       mask = 0xffffffff,      // mask
       sreg = 0x4,             // source register
       inv = 0x0,              // inverse, for not equal  
       len = 0x20,             // len of the expression = 4 + 4 + 1 + 1 
      }
// [ cmp eq reg 1 0x0900007f ]
</code></pre>
<p>Finally the last expression is to increment a counter ( per-cpu data )</p>
<pre><code class="language-c">(gdb) p ((struct nft_expr *)&amp;rule-&gt;data[40] )-&gt;ops
$53 = (const struct nft_expr_ops *) 0xffffffff846881a0 &lt;nft_counter_ops&gt;
(gdb) p *(struct nft_counter_percpu_priv*)((struct nft_expr *)&amp;rule-&gt;data[40])-&gt;data
$54 = {counter = 0x607fdda05ff0 }
// its percpu data

(gdb) p this_cpu
$84 = (struct nft_counter *) 0xffffe8ffffc05ff0
(gdb) p *this_cpu
$85 = {bytes = 504, packets = 6}

// [ counter pkts 5 bytes 504 ]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n53-adding-tables-chains-rules-userspace"><a class="header" href="#n53-adding-tables-chains-rules-userspace">N5.3 Adding tables, chains, rules (userspace)</a></h1>
<p>netlink messages are used to setup tables, chains, etc from userspace.</p>
<p>Let us dissect the netlink message that is sent by <code>nft</code> by running <code>strace</code> .  Some parts of the netlink message that are not parsed by <code>strace</code>, have also been formatted here.</p>
<pre><code class="language-sh">$ strace -f nft add table T2
</code></pre>
<p><code>nft</code> creates a netlink socket and first sends a request to get rule-set generation <code>NFT_MSG_GETGEN</code>. In response, we receive the generation, which in this case is 3.</p>
<pre><code class="language-c">socket(AF_NETLINK, SOCK_RAW, NETLINK_NETFILTER) = 3
sendto(3,
	{
        struct nlmsghdr {
            nlmsg_len=20,
            nlmsg_type=NFNL_SUBSYS_NFTABLES &lt;&lt; 8 | NFT_MSG_GETGEN, //&lt;- 0xa10
            nlmsg_flags=NLM_F_REQUEST,
            nlmsg_seq=0, nlmsg_pid=0
        },
        struct nfgenmsg{ // &lt;- &quot;\x00\x00\x00\x00&quot;
            nfgen_family=AF_UNSPEC,
            version = NFNETLINK_V0,
            res_id = 0,
        }
        
    },20,
    0,{sa_family=AF_NETLINK, nl_pid=0, nl_groups=00000000},12) = 20
    
recvmsg(3,
   {
       msg_name={
           sa_family=AF_NETLINK,
           nl_pid=0,
           nl_groups=00000000
       },
       msg_namelen=12,
       msg_iov=[
           {
               iov_base={
                   struct nlmsghdr {
                       nlmsg_len=44,
                       nlmsg_type=NFNL_SUBSYS_NFTABLES &lt;&lt; 8 | NFT_MSG_NEWGEN //&lt;- 0xa0f
                       nlmsg_flags=0,
                       nlmsg_seq=0,
                       nlmsg_pid=214676 // pid
                   },
                   struct nfgenmsg{ // &lt;-  &quot;\x00\x00\x00\x03&quot;
                            nfgen_family=AF_UNSPEC,
                            version = NFNETLINK_V0,
                            (be16) res_id = 0x0003, // nft_base_seq(net)
                   },
                   struct nlattr {
                       nla_len = 8, //&lt;- \x08\x00
                       nla_type = NFTA_GEN_ID, // &lt;- \x01\x00
                   },
                   data = htonl(nft_net-&gt;base_seq) &quot;\x00\x00\x00\x03&quot;,
                   padding = &quot;&quot;,
                   struct nlattr {
                       nla_len = 8, //&lt;- \x08\x00
                       nla_type = NFTA_GEN_PROC_PID, // &lt;- &quot;\x02\x00&quot;
                   },
                   data = htonl(pid), // &lt;- htonl(214676) = &quot;\x00\x03\x46\x94&quot;,
                   padding = &quot;&quot;,
                   struct nlattr {
                       nla_len = 8, //&lt;- \x08\x00
                       nla_type = NFTA_GEN_PROC_PID, // &lt;- &quot;\x03\x00&quot;
                   },
                   data=&quot;nft\0&quot;, // &lt;-&quot;\x6e\x66\x74\x00&quot;
                   padding = &quot;&quot;,
               },
               iov_len=69631
           }
       ],
       msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 44
</code></pre>
<p>netfilter stores the generation number in <code>struct nftables_pernet</code> , which is data that is maintained per network namespace.</p>
<pre><code class="language-c">struct nftables_pernet *nft_net = nft_pernet(net);

struct nftables_pernet {
    struct list_head	tables; // list of tables
    struct list_head    commit_list; // list of transactions that are pending
    ...
    struct mutex        commit_mutex;
    unsigned int        base_seq; // generation number
};
</code></pre>
<p>Next, nft constructs and sends a netlink message to setup the table. netlink messages have sections each with a netlink message header and it's attributes.  <code>nlmsghdr-&gt;nlmsg_type</code> lets the kernel handle the section accordingly. In the below message we have the following sections:</p>
<ol>
<li><code>NFNL_MSG_BATCH_BEGIN</code>: begin a batch of changes to the ruleset</li>
<li><code>NFT_MSG_NEWTABLE</code> : create a new table, with attributes:
<ol>
<li><code>NFTA_TABLE_NAME</code>:  <code>&quot;T2\0&quot;</code></li>
<li><code>NFTA_TABLE_FLAGS</code>: 0</li>
</ol>
</li>
<li><code>NFNL_MSG_BATCH_END</code>: end of batch. Now commit these changes (which happens atomically as we will see in a later section).</li>
</ol>
<pre><code class="language-c">sendmsg(3,
    {
        msg_name={
            sa_family=AF_NETLINK,
            nl_pid=0,
            nl_groups=00000000
        },
        msg_namelen=12,
        msg_iov=[
            {
                iov_base=[
                    {
                        struct nlmsghdr {
                            nlmsg_len=20,
                            nlmsg_type=NFNL_MSG_BATCH_BEGIN, //&lt;- 0x10
                            nlmsg_flags=NLM_F_REQUEST,
                            nlmsg_seq=0, 
                            nlmsg_pid=0
                        },
                        struct nfgenmsg{ // &lt;- &quot;\x00\x00\x0a\x00&quot;
                            nfgen_family=AF_UNSPEC,
                            version = NFNETLINK_V0,
                            res_id = NFNL_SUBSYS_NFTABLES, /*resource id */
                        }
                    },
                    {
                        struct nlmsghdr {
                            nlmsg_len=36,
                            nlmsg_type=NFNL_SUBSYS_NFTABLES &lt;&lt; 8 | NFT_MSG_NEWTABLE, // &lt;- 0xa00
                            nlmsg_flags=NLM_F_REQUEST,
                            nlmsg_seq=1,
                            nlmsg_pid=0
                        },
                         struct nfgenmsg{ // &lt;- &quot;\x02\x00\x00\x00&quot;
                            nfgen_family=AF_INET,
                            version = NFNETLINK_V0,
                            res_id = 0, /*resource id */
                        }
                        struct nlattr {
                            nla_len = 7, // &lt;- &quot;\x07\x00&quot;
                            nla_type = NFTA_TABLE_NAME, //&lt;- &quot;\x01\x00&quot;
                        },
                        data = &quot;T2\0&quot;,  // &lt;- &quot;\x54\x32\x00&quot;
                        padding = &quot;\x00&quot;, // 4 byte alignment
                        
                        struct nlattr {
                            nla_len = 8, // &lt;- &quot;\x08\x00&quot;
                            nla_type = NFTA_TABLE_FLAGS //  &quot;\x02\x00&quot;
                        },
                        (u32) flags = 0, // &lt;- \x00\x00\x00\x00&quot;,
                    },
                    {
                        struct nlmsghdr {
                            nlmsg_len=20,
                            nlmsg_type=NFNL_MSG_BATCH_END,
                            nlmsg_flags=NLM_F_REQUEST, 
                            nlmsg_seq=2, 
                            nlmsg_pid=0,
                        }, 
                        struct nfgenmsg{ // &lt;- &quot;\x00\x00\x0a\x00&quot;
                            nfgen_family=AF_UNSPEC,
                            version = NFNETLINK_V0,
                            res_id = NFNL_SUBSYS_NFTABLES, /*resource id */
                        }
                    }
                ], 
                iov_len=76
            }
        ], 
        msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 76
</code></pre>
<p>Though I wont show strace output, to setup a chain will have a netlink message with <code>NFT_MSG_NEWCHAIN</code>  and attributes <code>NFTA_CHAIN_TABLE</code>,  <code> NFTA_CHAIN_NAME</code> , <code>NFTA_CHAIN_HOOK</code> and<code>NFTA_CHAIN_POLICY</code>. </p>
<p>And to setup a rule nft will send a message with <code>NFT_MSG_NEWRULE</code> and attributes <code>NFTA_RULE_TABLE</code>, <code>NFTA_RULE_CHAIN</code>  and most importantly <code>NFTA_RULE_EXPRESSIONS</code> which is shown below.</p>
<p>Note: use <code>--string-limit</code> so strace dumps the complete msg data.</p>
<pre><code class="language-sh">strace -f --string-limit=1024  -o one.txt nft add rule T C ip daddr 127.0.0.9 counter
</code></pre>
<pre><code class="language-c">sendmsg(3,
   {msg_name=
       {sa_family=AF_NETLINK,
        nl_pid=0,
        nl_groups=00000000},
    msg_namelen=12,
    msg_iov=[
      {iov_base=[
        {
            struct nlmsghdr {
                nlmsg_len=20,
                nlmsg_type=NFNL_MSG_BATCH_BEGIN, // &lt;- 0x10,
                nlmsg_flags=NLM_F_REQUEST,
                nlmsg_seq=0,
                nlmsg_pid=0},
            struct nfgenmsg { // &lt;- &quot;\x00\x00\x0a\x00&quot;
                nfgen_family=AF_UNSPEC,
                version = NFNETLINK_V0,
                res_id = NFNL_SUBSYS_NFTABLES, /*resource id */
            }
        },
        {
            struct nlmsghdr {
                nlmsg_len=156,
                nlmsg_type= NFNL_SUBSYS_NFTABLES &lt;&lt; 8 | NFT_MSG_NEWRULE, // &lt;- 0xa06
                nlmsg_flags=NLM_F_REQUEST|0xc00,
                nlmsg_seq=1,
                nlmsg_pid=0
            },
            struct nfgenmsg { // &lt;- &quot;\x02\x00\x00\x00&quot;
                nfgen_family=AF_INET,
                version = NFNETLINK_V0,
                res_id = 0,
            },
            struct nlattr {
                nla_len = 6,       // &quot;\x06\x00&quot;
                nla_type = NFTA_RULE_TABLE, // &lt;- &quot;\x01\x00&quot;
            },                       
            data =  &quot;T\0&quot;, //   &quot;\x54\x00
            padding = &quot;\x00\x00&quot;,
            struct nlattr {
                nla_len = 6, // &lt;- \x06\x00
                nla_type = NFTA_RULE_CHAIN, // &lt;- &quot;\x02\x00&quot;
            },
            data = &quot;C\0&quot;, // \x43\x00
            padding = &quot;\x00\x00&quot;,
            struct nlattr {
                nla_len = 120, //&lt;-  \x78\x00,
                nla_type = NLA_F_NESTED | NFTA_RULE_EXPRESSIONS, //&lt;-\x04\x80
            }

            {
                // 1. payload load 4b @ network header + 16 =&gt; reg 1
                struct nlattr {
                    nla_len = 52, //&lt;- &quot;\x34\x00&quot;
                    nla_type = NLA_F_NESTED | NFTA_LIST_ELEM,  //&lt;- \x01\x80
                }
                struct nlattr {
                    nla_len = 12, //&lt;- \x0c\x00
                    nla_type = NFTA_EXPR_NAME, // &lt;- \x01\x00
                }
                data = &quot;payload\0&quot;,  // &lt;- &quot;\x70\x61\x79\x6c\x6f\x61\x64\x00&quot;,
                padding = &quot;&quot;,
                struct nlattr {
                    nla_len = 36, // \x24\x00
                    nla_type = NLA_F_NESTED | NFTA_EXPR_DATA, //&lt;- &quot;\x02\x80&quot;
                }
                struct nlattr {
                    nla_len = 8, // \x08\x00
                    nla_type = NFTA_PAYLOAD_DREG // &lt;- \x01\x00
                }
                data = 1, //&lt;-  &quot;\x00\x00\x00\x01&quot;
                payload = &quot;&quot;,
                struct nlattr {
                    nla_len = 8, //&lt;- \x08\x00
                    nla_type = NFTA_PAYLOAD_BASE,//&lt;- \x02\x00
                }
                data = NFT_PAYLOAD_NETWORK_HEADER, //&lt;-\x00\x00\x00\x01
                padding = &quot;&quot;,
                struct nlattr {
                    nla_len = 8, //\x08\x00
                    nla_type = NFTA_PAYLOAD_OFFSET ,//\x03\x00
                }
                data = 16, // \x00\x00\x00\x0f,
                padding = &quot;&quot;,
                struct nlattr {
                    nla_len = 8, //\x08\x00
                    nla_type = NFTA_PAYLOAD_LEN // \x04\x00
                }
                data = 4, //&quot;\x00\x00\x00\x04&quot;
                padding = &quot;&quot;,
            }
            {
                //2. cmp eq reg 1 0x0900007f
                struct nlattr {
                    nla_len = 44, // &lt;-\x2c\x00
                    nla_type = NLA_F_NESTED | NFTA_LIST_ELEM, //&lt;- \x01\x80
                }
                struct nlattr {
                    nla_len = 8, // \x08\x00
                    nla_type = NFTA_EXPR_NAME //\x01\x00
                }
                data = &quot;cmp\0&quot;, //&quot;\x63\x6d\x70\x00&quot;
                payload = &quot;&quot;,
                struct nlattr {
                    nla_len = 32, // &lt;-\x20\x00
                    nla_type = NLA_F_NESTED | NFTA_EXPR_DATA // \x02\x80
                }
                struct nlattr {
                    nla_len = 8, //\x08\x00
                    nla_type = NFTA_CMP_SREG // \x01\x00
                }
                data = 1, // \x00\x00\x00\x01
                padding = &quot;&quot;,
                struct nlattr {
                    nla_len = 8, //\x08\x00,
                    nla_type = NFTA_CMP_OP, //\x02\x00
                }
                data =NFT_CMP_EQ, // = 0 &lt;- &quot;\x00\x00\x00\x00&quot;,
                padding = &quot;&quot;,
                struct nlattr {
                    nla_len = 12, //\x0c\x00
                    nla_type = NLA_F_NESTED | NFTA_CMP_DATA, //\x03\x80
                }
                struct nlattr {
                    nla_len = 8, //\x08\x00
                    nla_type = NFTA_DATA_VALUE, // \x01\x00
                }
                data = 0x0900007f, //&quot;\x7f\x00\x00\x09&quot;
                padding = &quot;&quot;,

            }
            {
                // 3. counter pkts 0 bytes 0 
                struct nlattr {
                    nla_len = 20, //\x14\x00
                    nla_type = NLA_F_NESTED | NFTA_LIST_ELEM, //\x01\x80
                }
                struct nlattr {
                    nla_len = 12, //\x0c\x00
                    nla_type = NFTA_EXPR_NAME, // \x01\x00
                }
                data = &quot;counter\0&quot;, // &quot;\x63\x6f\x75\x6e\x74\x65\x72\x00&quot;
                padding = &quot;&quot;,
                struct nlattr {
                    nla_len = 4 , // \x04\x00
                    nla_type = NLA_F_NESTED | NFTA_EXPR_DATA, //\x02\x80
                    // nested but len is 4 =&gt; no additional data 
                }
            }
        },
        {
            {
                nlmsg_len=20,
                nlmsg_type=NFNL_MSG_BATCH_END, // &lt;- 0x11,
                nlmsg_flags=NLM_F_REQUEST,
                nlmsg_seq=2,
                nlmsg_pid=0},
            struct nfgenmsg { // &lt;- &quot;\x00\x00\x0a\x00&quot;
                nfgen_family=AF_UNSPEC,
                version = NFNETLINK_V0,
                res_id = NFNL_SUBSYS_NFTABLES, /*resource id */
            }
        }
    ], iov_len=196}
  ], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 1
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n54-adding-tables-chains-rules-kernel"><a class="header" href="#n54-adding-tables-chains-rules-kernel">N5.4 Adding tables, chains, rules (kernel)</a></h1>
<p>Netlink messages are handled in  nfnetlink_rcv_batch()</p>
<pre><code class="language-c">(gdb) bt
#0  nfnetlink_rcv_batch
#1  nfnetlink_rcv_skb_batch
#2  nfnetlink_rcv
#3 netlink_unicast_kernel
#4  netlink_unicast
#5  netlink_sendmsg
#6  sock_sendmsg_nosec
#7  sock_sendmsg
#8  ____sys_sendmsg
</code></pre>
<p>An overview of how the data is handled in <code>nfnetlink_rcv_batch</code>:</p>
<ol>
<li>Hold the <code>nftables_pernet-&gt;commit mutex</code></li>
<li>Add each change as a transaction into <code>nftables_pernet-&gt;commit_list</code>.</li>
<li>Commit changes in <code>nf_tables_commit</code></li>
<li>Release lock <code>nftables_pernet-&gt;commit mutex</code></li>
</ol>
<pre><code class="language-c">static void nfnetlink_rcv_batch(struct sk_buff *skb, struct nlmsghdr *nlh, 
                                u16 subsys_id, u32 genid)
{
    struct net *net = sock_net(skb-&gt;sk); // same namespace as the process
    
    // subsys_id = NFNL_SUBSYS_NFTABLES
    ss = nfnl_dereference_protected(subsys_id);
    /* ss = struct nfnetlink_subsystem nf_tables_subsys {
    		.cb				= nf_tables_cb,
    		.commit			= nf_tables_commit,
    		.valid_genid	= nf_tables_valid_genid,
    	} */
    
    nc = nfnetlink_find_client(type, ss);
    
    ss-&gt;valid_genid(net, genid)
    {
        
        struct nftables_pernet *nft_net = nft_pernet(net);
        mutex_lock(&amp;nft_net-&gt;commit_mutex);
    }
    
    while (skb-&gt;len &gt;= nlmsg_total_size(0)) {
        type = nlh-&gt;nlmsg_type;
        if (type == NFNL_MSG_BATCH_BEGIN) {
            /* Malformed: Batch begin twice */
            status |= NFNL_BATCH_FAILURE;
            goto done;
        } else if (type == NFNL_MSG_BATCH_END) {
            status |= NFNL_BATCH_DONE;
            goto done;
        } else if (type &lt; NLMSG_MIN_TYPE) {
            err = -EINVAL;
            goto ack;
        }
        
        nc = nfnetlink_find_client(type, ss); // call back
        // nc is picked from nf_tables_cb
        {
            return &amp;ss-&gt;cb[cb_id]
        }
        
        err = nc-&gt;call(skb, &amp;info, (const struct nlattr **)cda);
        // create a table and add transaction to commit_list
    }

    err = ss-&gt;commit(net, oskb);
    // nf_tables_commit(struct net *net, struct sk_buff *skb)
    {
     	list_for_each_entry_safe(trans, next, &amp;nft_net-&gt;commit_list, list) {
            // based  on the transaction type, commit it
        }
        nf_tables_commit_release(net)
        {
            // some clean-up and finally unlock mutex
            mutex_unlock(&amp;nft_net-&gt;commit_mutex);
        }
    }
    if (err) {
        ss-&gt;abort(net, oskb, NFNL_ABORT_NONE);
    }

}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="n55-atomic-transactions"><a class="header" href="#n55-atomic-transactions">N5.5 Atomic Transactions</a></h1>
<p>begin and end transactions, all instructions within the them are committed in one go.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="m-miscellaneous"><a class="header" href="#m-miscellaneous">M. Miscellaneous</a></h1>
<p>Either notes that I have not sorted or ones that don't require a dedicated section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cse-222a-notes"><a class="header" href="#cse-222a-notes">CSE 222a, Notes</a></h1>
<p>This page contains summaries of the various papers I read as a part of CSE222a, at UCSD. It was taught by Prof. George Porter. The course focused on reading classical and current papers followed by in class discussions. The following are papers that I found interesting. Most of the summaries usually consist of four paragraphs:</p>
<ol>
<li>the introduction, problem its trying to solve, the pain points</li>
<li>the idea, how it solves the problem</li>
<li>their implementation</li>
<li>their results and my thoughts</li>
</ol>
<p>Some of these papers cannot be uploaded/shared. I have provided links to some of the papers if I was able to find a public link off DuckDuckGo. Else I have provided a private link which needs subscription. In case you cannot access them, send me a mail and if possible I'll share the paper.</p>
<h3 id="m11-early-internet-darpa-internet-protocols"><a class="header" href="#m11-early-internet-darpa-internet-protocols">M1.1 Early Internet, Darpa Internet Protocols</a></h3>
<p>These papers describe the structure of an early internet. The first paper is a description of the components in building a packet switching network. The second one, published 14 years later is a description the design goals and the protocols developed.</p>
<h5 id="paper-1-a-protocol-for-packet-network-incommunication-ieee-1974-a-hrefhttpswwwcsprincetoneducoursesarchivefall06cos561paperscerf74pdflinka"><a class="header" href="#paper-1-a-protocol-for-packet-network-incommunication-ieee-1974-a-hrefhttpswwwcsprincetoneducoursesarchivefall06cos561paperscerf74pdflinka">Paper 1. A Protocol for Packet Network Incommunication (IEEE 1974) [<a href="https://www.cs.princeton.edu/courses/archive/fall06/cos561/papers/cerf74.pdf">Link</a>]</a></h5>
<p>The paper first clearly defines the components of the network viz Hosts, networks and gateways. The hosts as the end points which are connected to each other. Multiple hosts are connected to internetwork. And internetworks are connected via Gateways. Each internetwork can use its own protocol for communication. But communication across internetworks needed a common protocol. The protocol for internetwork communication is the early IP protocol. The authors then describe a protocol over the internetwork protocol to transfer data between end points.</p>
<p>The protocols described are similar to modern implementations of IP and TCP headers. The original vision of the packet switching network remains very similar to our current networks. The paper clearly explains their choice for a common internetwork protocol, while each network was free to develop protocols for communication within the network. Th Gateway simply handled translation between the network protocols. This is very clearly the design that we still adopt, except that hosts very rarely communicate on bare link local protocol. Most communication, even between hosts within a network, is over IP. The authors choice to have a common IP protocol implemented by all hosts which we have acknowledge today as the narrow waist of the internet. Other differences include fragmentation using sequence numbers, which have now moved to TCP, while IP implements a blunt form of fragmentation.</p>
<p><img src="M/imgs/M1_interntwhdr.svg" alt="M1_interntwhdr" /></p>
<p>The authors describe the transmission control protocol as a means to transmit a stream of data, which it breaks into segments. Early TCP used the sequence numbers provided by internetwork protocol, and both the protocols worked closely to transmit data. Modern IP and TCP have been separated into distinct protocols with independent functions. The authors also have a section which describes early address format and address assignment which have completely changed. The authors also envision a central repository that provides addresses for each node within a network, which in way the current DHCP implementation.</p>
<p>The paper is a description of the network that the authors envisioned, some of their decisions have formed the basis of the current internet.</p>
<h5 id="paper-2-the-design-philosophy-of-the-darpa-internet-protocols-acm-1988-a-hrefhttpsgroupscsailmiteduanapublicationspubpdfsthe20design20philosophy20of20the20darpa20internet20protocolspdflinka"><a class="header" href="#paper-2-the-design-philosophy-of-the-darpa-internet-protocols-acm-1988-a-hrefhttpsgroupscsailmiteduanapublicationspubpdfsthe20design20philosophy20of20the20darpa20internet20protocolspdflinka">Paper 2. The Design Philosophy of the DARPA Internet Protocols (ACM 1988) [<a href="https://groups.csail.mit.edu/ana/Publications/PubPDFs/The%20design%20philosophy%20of%20the%20DARPA%20internet%20protocols.pdf">Link</a>]</a></h5>
<p>The second paper describes the philosophy behind the design of the Internet protocols after the protocols had standardised. The paper first describes the fundamental goals of the network. Then they describe how these goals influence the design.</p>
<p>One of the foremost goals was for the network to and continue working despite loss. This goal was adopted since the network was initially a military project that was later released for civil use. This made the internet fault tolerant at the expense of performance. To achieve this, the state necessary for internet functioning is moved to the endpoints. This approach is described as &quot;fate sharing&quot; since both entity and the state share the same fate. A consequence of this approach was the stateless design of switches and gateways. Also, each end node is responsible for maintaining any state necessary for the connection. It is interesting that the goal and the chosen approach is applied in current network designs.</p>
<p>The paper then describes the services supported over IP and the need for a protocol that allows the user to use the datagram services offered by IP. This created a need for decoupling IP and TCP, and building the User Datagram Protocol as the protocol which offers these services. The paper then describes the division into layers which offer services independently using services offered by lower layers. The classical OSI model is the modern form of this idea, with clear abstractions of the functions provided by each layer.</p>
<h3 id="m12-distributed-computation-of-a-spanning-tree-in-an-extended-lan"><a class="header" href="#m12-distributed-computation-of-a-spanning-tree-in-an-extended-lan">M1.2 Distributed Computation of a Spanning Tree in an Extended LAN</a></h3>
<h5 id="paper-an-algorithm-for-distributed-computation-of-a-spanning-tree-in-an-extended-lan-acm-1985-a-hrefhttpswwwituuseeducoursehomepagedatakomht06slidessta-perlmanpdflinka"><a class="header" href="#paper-an-algorithm-for-distributed-computation-of-a-spanning-tree-in-an-extended-lan-acm-1985-a-hrefhttpswwwituuseeducoursehomepagedatakomht06slidessta-perlmanpdflinka">Paper: An Algorithm for Distributed Computation of a Spanning Tree in an Extended LAN (ACM 1985) [<a href="https://www.it.uu.se/edu/course/homepage/datakom/ht06/slides/sta-perlman.pdf">Link</a>]</a></h5>
<p>The author describes a algorithm to build a tree from an extended LAN. As networks began to grow, with LANs interconnected using bridges to build an extended LAN, manual configuration of the bridges increased the risk of loops. Similarly a user without proper knowledge could connect LANs with a bridge and create a Loop. The proposed algorithm allows the bridges to exchange data and construct a tree without any additional configuration. Secondly the algorithm converges in O(mesh diameter) while imposing small memory requirements (proportional to the number of LANs the bridge is connected to) on each bridge.</p>
<p><img src="M/imgs/M1_extended_LAN.svg" alt="extended_lan" /></p>
<p>In the final tree, each LAN has a designated bridge. On receiving data from a LAN, a bridge forwards the data to all other LANs on which it is a designated bridge. The complete mesh is transformed into a tree by choosing the designated bridges. The root of the tree is a designated bridge on all of it's LANs. The algorithm chooses a very simple way to choose the root. The bridge with the smallest MAC value is chosen as the root. The bridges exchange HELLO messages to find the root. Once a root is found, the root sends out periodic HELLO messages. These HELLO messages are forwarded on all connected LANs. The bridges based on the HELLO messages share information and choose the designated bridge on each LAN. The algorithm works by each bridge first trying to become the root and then trying to become the designated brigde on each of the LANs it is connected to.</p>
<p>The paper also describes states maintained by the bridge for each LAN and transitions between states to prevent loops due to new bridges being added. Also, the HELLO messages timeout letting the bridge detect failures in the network. This has been described in detail in the paper and I cannot sufficiently describe it in a single paragraph.</p>
<p><img src="M/imgs/M1_ex_LAN_tree2.svg" alt="ext_bridge" /></p>
<p>Bridge 1 becomes the leader, dotted links are in backup state. Arrows are links in forwarding state, pointing towards non leader bridges.</p>
<p>It is always nice to see a simple distributed algorithm which solves the problem. What is especially refreshing is the poem she wrote as a part of the abstract, which summarises the algorithm succinctly.</p>
<p><em>I think that I shall never see</em>
<em>A graph more lovely than a tree</em></p>
<p><em>A tree whose crucial property</em>
<em>Is loop-free connectivity.</em></p>
<p><em>A tree which must be sure to span</em>
<em>So packets can reach every LAN.</em></p>
<p><em>First the Root must be selected</em>
<em>By ID it is elected.</em></p>
<p><em>Least cost paths from Root are traced.</em>
<em>In the tree these paths are placed</em></p>
<p><em>A mesh is made by folks like me</em>
<em>Then bridges find a spanning tree.</em></p>
<h3 id="m13-network-protocol-folklore"><a class="header" href="#m13-network-protocol-folklore">M1.3 Network Protocol Folklore</a></h3>
<h5 id="paper-network-protocol-folklore-acm-2019-a-hrefhttpsccronlinesigcommorgwp-contentuploads201910acmdl19-336pdflinka"><a class="header" href="#paper-network-protocol-folklore-acm-2019-a-hrefhttpsccronlinesigcommorgwp-contentuploads201910acmdl19-336pdflinka">Paper: Network Protocol Folklore (ACM 2019) [<a href="https://ccronline.sigcomm.org/wp-content/uploads/2019/10/acmdl19-336.pdf">Link</a>]</a></h5>
<p>Radia Perlman, having been working on internet protocols since it's inception, shares a history of choices they made and their consequences on the modern internet implementation. One line from the abstract which makes the paper interesting is: Some decisions have made today’s networks unnecessarily complex and less functional. Surprisingly, mechanisms that were created out of necessity, to compensate for previous decisions, sometimes turn out to be useful for purposes other than the original reason they were invented.</p>
<p>Ethernet addresses were designed to be 6 bytes long so that nodes connected over ethernet would not need any other address configuration. But ethernets never have more than a few thousand nodes attached. Each ethernet address is unique and location independent, but are simply used for link to link transfer. It is interesting that IPv4, which was designed so each node would get a unique address dynamically has a smaller length of just 4 Bytes. People even envisioned ethernet as Layer 3 replacement, implementing end to end connections over ethernet due to the uniqueness property of the ethernet address.</p>
<p>DEC had developed an alternate to IP called IS-IS which adopted CLNP (ConnectionLess Network Protocol) addressing. CNLP has very large 20 Byte addresses ( larger than 16Byte IPv6). Though it did not catch on CNLP supported features that were later built into IPv6.</p>
<p>The paper has a brief overview of the history behind the spanning tree protocol. Customers expected nodes in different ethernets to work. DEC sold routers which routed based on Layer 3 addresses, but expected end nodes to implement Layer 3 to route between different ethernets. The author argues that the right solution was for all endpoints to put Layer 3 into the stack for such inter ethernet communication. But, DEC decided that instead of waiting for endpoints to upgrade, it was easier to build a network box which routed based on ethernet addresses, i.e. the bridge. Radia Perlman was asked to design an algorithm to break ethernet routing loops. The resulting algorithm, the spanning tree algorithm, a temporary fix till endpoints upgrade their network stacks is still being widely deployed.</p>
<p>The paper compares CLNP and modern IPv6. A few features of CLNP are:</p>
<ul>
<li>Autoconfiguration by appending 14 byte network prefix with the 6 Byte ethernet address to build a complete 20Byte address.</li>
<li>The network prefix is hierchically assigned based on region.</li>
<li>Within an area since the prefix is common, nodes can move anywhere in the area without changing the address.</li>
<li>Since CLNP had ethernet address, ethernet header could be dropped so CLNP is used for both Layer 2 and 3 routing.</li>
</ul>
<p>IPv4 addressing was not as scalable as CLNP and does not support movement within an area without address reconfiguration (especially helpful with Datacenters migrating VMs). IP is a flat address space with ethernet providing functionality of a region. One consequence of IP and ethernet being completely independent is that we need the ARP protocol to discover the endnode's ethernet address. CLNP on the other hand needed each node to anounce it's location.</p>
<p>The paper then moves to the final section which are surprising outcomes of the decisions people took.</p>
<ul>
<li>Seperation of IP and Ethernet allowed VLAN, which provides the ability to configure which nodes can talk. This is used in datacenters to build a LAN for a group of VMs.</li>
<li>Since CLNP uses a unique ethernet address which is then announced to everyone, tracking using CLNP would have been easier making it a major privacy issue. Instead since IP is ephemeral, tracking though possible is less intrusive.</li>
<li>NATs were built to fix IPv4's inability to scale, not necessary for CLNP. But NATs have become a major security feature to obfusicate users behind a NAT. Also since users behind a NAT cannot be contacted without the user initiating a connection, the users are protected from external nodes.</li>
</ul>
<hr />
<h3 id="the-ones-below-are-incomplete"><a class="header" href="#the-ones-below-are-incomplete">The ones below are incomplete</a></h3>
<h3 id="m14-classic-multicast-routing"><a class="header" href="#m14-classic-multicast-routing">M1.4 Classic Multicast Routing</a></h3>
<p>Multicast Routing in Datagram Internetworks and Extended LANs</p>
<p>The paper is the seminal paper on how multicast can be implemented with support from the bridges. The paper proposes minor modifcations to routing algorithms to facilitate multicast.</p>
<h3 id="m15-bgp-interdomain-routing"><a class="header" href="#m15-bgp-interdomain-routing">M1.5 BGP: Interdomain Routing</a></h3>
<p>eBGP and iBGP, sharing routing information.</p>
<h3 id="m16-end-to-end-routing-behavior"><a class="header" href="#m16-end-to-end-routing-behavior">M1.6 End to End Routing Behavior</a></h3>
<p>Radia Perlman</p>
<h3 id="m17-narada-end-system-multicast"><a class="header" href="#m17-narada-end-system-multicast">M1.7 Narada: End System Multicast</a></h3>
<p>Radia Perlman</p>
<h3 id="m18-active-network-architecture"><a class="header" href="#m18-active-network-architecture">M1.8 Active Network Architecture</a></h3>
<p>Radia Perlman</p>
<h3 id="m19-click-modular-router"><a class="header" href="#m19-click-modular-router">M1.9 Click Modular Router</a></h3>
<p>Radia Perlman</p>
<h3 id="m110-open-flow"><a class="header" href="#m110-open-flow">M1.10 Open Flow</a></h3>
<p>Radia Perlman</p>
<h3 id="m111-congestion-avoidance-and-control"><a class="header" href="#m111-congestion-avoidance-and-control">M1.11 Congestion Avoidance and Control</a></h3>
<p>Reno TCP</p>
<h3 id="m112-fast-switched-backplane-for-a-gigabit-switched-router"><a class="header" href="#m112-fast-switched-backplane-for-a-gigabit-switched-router">M1.12 Fast Switched Backplane for a Gigabit Switched Router</a></h3>
<p>iSlip</p>
<h3 id="m113-p4-programming-protocol-independent-packet-processors"><a class="header" href="#m113-p4-programming-protocol-independent-packet-processors">M1.13 P4: Programming Protocol Independent Packet Processors</a></h3>
<p>p4
M1.14 SWAN</p>
<h3 id="swan-achieving-high-utilization-with-software-driven-wan"><a class="header" href="#swan-achieving-high-utilization-with-software-driven-wan">SWAN: Achieving High Utilization with Software Driven WAN</a></h3>
<p>M1.15 Fat Trees</p>
<h3 id="scalable-commodity-data-center-network-arch"><a class="header" href="#scalable-commodity-data-center-network-arch">scalable commodity data center network arch</a></h3>
<h3 id="m116-portland"><a class="header" href="#m116-portland">M1.16 PortLand</a></h3>
<p>fault tolerant l2 data center</p>
<h3 id="m117-jellyfish"><a class="header" href="#m117-jellyfish">M1.17 Jellyfish</a></h3>
<h3 id="m118-dctcp"><a class="header" href="#m118-dctcp">M1.18 DCTCP</a></h3>
<h3 id="m119-mptcp"><a class="header" href="#m119-mptcp">M1.19 MPTCP</a></h3>
<h3 id="m120-open-vswitch"><a class="header" href="#m120-open-vswitch">M1.20 Open vSwitch</a></h3>
<h3 id="m121-eyeq"><a class="header" href="#m121-eyeq">M1.21 EyeQ</a></h3>
<h3 id="m122-censorship-in-china"><a class="header" href="#m122-censorship-in-china">M1.22 Censorship in China</a></h3>
<p>great firewall</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cache-side-channel-attacks"><a class="header" href="#cache-side-channel-attacks">Cache Side Channel Attacks</a></h1>
<p>By design caches are transparent, but processes can create contention resulting in timing variations.    CPU data cache timing attacks are to exploit cache timing to expose cache's internal state. </p>
<p>Caches are one place where time variations can be exposed.  Caches are built to bridge the gap between main memory and Processor  registers. Since it takes fewer cycles to read from cache than from main memory, recording time differences makes reading from cache detectable.</p>
<h3 id="caches-recap"><a class="header" href="#caches-recap">Caches Recap:</a></h3>
<ul>
<li>Caches are designed to exploit spatial locality in memory access</li>
<li>For each read, check if the data is present in one of the  caches. If present, read from the cache or load from lower memory. LRU  to evict old entries. </li>
<li>Cold cache misses are when the cache is empty, happens during program load.</li>
<li>Data can only be added to certain regions in the cache.  Multiple address lines in lower memory map to a subset in the cache.  Conflict miss happens when data that map to the same region are being  loaded, causing unnecessary cache evictions.</li>
<li>If cache size is larger than the working set of memory, we face capacity misses.</li>
<li>Write through cache: each write is immediately written to lower levels. Simple logic, but increases bus traffic</li>
<li>Write-back cache: write to cache, defer updating lower levels till it is evicted from the cache.</li>
<li>Cache Coherence: The same data can be present on multiple  caches, if one of the processors makes a change to common data, the  processor needs to make sure that cached data is consistent.</li>
<li>A Cache Coherence protocol makes sure of cache coherence  among caches. Cache coherence protocols described below are snooping  protocols, i.e. changes to cache traffic is visible to all cores.</li>
<li>Write-invalidate: On detecting a write to another cached location, invalidate local copy, forcing a read from main memory.</li>
<li>Write-update: On detecting a write, update local copy.</li>
<li>Any cache coherence protocol increases bus traffic. </li>
<li>Article on cache coherence : <a href="https://fgiesen.wordpress.com/2014/07/07/cache-coherency/">https://fgiesen.wordpress.com/2014/07/07/cache-coherency/</a> </li>
<li>Notes on CPU caches: <a href="https://www.cse.iitb.ac.in/%7Emythili/os/notes/notes-cache.txt">https://www.cse.iitb.ac.in/~mythili/os/notes/notes-cache.txt</a>
<ul>
<li>has a clean explanation of MESI cache coherence protocol.</li>
</ul>
</li>
<li>Code patterns to improve cache performance:
<ul>
<li>Build loops, which operate on the same data. Merge loops if necessary</li>
<li>Within a data structure, make sure critical (read/write heavy) elements are cache aligned and at the top.</li>
<li>Reduce branches so code can be prefetched.</li>
<li>Atomic variables are allowed to be present only in one  cache. Use of atomic variables (and hence locks and synchronization  mechanisms) on multiple cores increases cache coherence traffic. </li>
<li>Instead try to use per CPU data structures.</li>
</ul>
</li>
</ul>
<h3 id="flushreload-paradigm"><a class="header" href="#flushreload-paradigm">Flush+Reload Paradigm.</a></h3>
<ul>
<li>Exploits Cache behavior to leak information about victim process.</li>
<li>Flush a line, wait for some time, measure access time. If  the victim has accessed the memory, access time will be in cache and  access will be fast. Else will be slow.</li>
<li>Repeat to identify victim's memory regions.</li>
<li>Slides Link: <a href="https://cs.adelaide.edu.au/%7Eyval/CHES16/">https://cs.adelaide.edu.au/~yval/CHES16/</a></li>
</ul>
<h3 id="spectre-1-bounds-check-bypass"><a class="header" href="#spectre-1-bounds-check-bypass">Spectre 1: Bounds Check Bypass:</a></h3>
<ul>
<li>
<p>Modern CPUs can speculatively execute instructions in a branch, before a branch true execution starts. </p>
</li>
<li>
<pre><code>int some_function(int user_input)
{
    int x = 0;
    int flush_reload_buffer[256];
    if (check user_input) {  // on checking user_input, undo changes to x
        x = secret_array[user_input];  // this is executed. before check.
                                       // contents leak into the cache.
    }
    y = flush_reload_buffer[x];
    leak = measure_access_time_of_all_elements(flush_reload_buffer);
} 
</code></pre>
</li>
<li>
<p>The CPU based on historic data, tries to predict branches and  executes instructions in the branch. Later it checks the branch check,  if the instructions it ran were incorrect, it undoes all the changes.  These changes are transparent for the user. But the instructions in the  branch load data into the cache. This data can then be identified by  cache timing.</p>
</li>
<li>
<p>This can be used to read data from the kernel via eBPF JIT.  Users can provide eBPF  bytecode which the kernel runs at certain kernel hooks. The bytecode is translated into machine code using a JIT engine.</p>
</li>
<li>
<p>HW Solution is to clean up cache while undoing changes. </p>
</li>
</ul>
<h3 id="spectre-2-branch-target-injection"><a class="header" href="#spectre-2-branch-target-injection">Spectre 2: Branch target injection:</a></h3>
<ul>
<li>Independent execution of the same code, can influence branch predictions. Earlier people worked on inferring  details about the  victim based on attacker's branch prediction. This attack instead forces victim's branch prediction due to attacker's choice of branch  execution.</li>
<li>Most branch predictors maintain a table of branches to jump  addresses. The last 12 bits are used to identify the branches and  addresses.</li>
<li>Since Only the last 12 bits are used, the attacker fills the table with branch and jump entries. The CPU while executing the victim  code enters the branch and loads the secret into the cache, which is  then read by the attacker. Note that the victim might itself have never  entered the branch, but the CPU speculatively executes the branch.</li>
<li>This can be used to read the host's memory from a KVM guest.</li>
<li>HW Solution: Update microcode so OS can control branch prediction table. </li>
<li>SW Retpoline Solution: Retpoline = return + trampoline. An  indirect branch that is not subject to speculative execution. Instead of a &quot;jmp&quot; use a call and return. <a href="https://support.google.com/faqs/answer/7625886">Google Blog.</a></li>
</ul>
<h3 id="spectre-3-rogue-data-cache-load"><a class="header" href="#spectre-3-rogue-data-cache-load">Spectre 3: Rogue data cache load</a></h3>
<ul>
<li>
<p>This attack exploits the fact that the CPU executes instructions in parallel, sometimes out of order to achieve parallelism.</p>
</li>
<li>
<pre><code>mov rax, [Somekerneladdress]
mov rbx, [someusermodeaddress] 
</code></pre>
</li>
<li>
<p>In the above example, the first instruction causes an  exception. But if the CPU runs both of them in parallel, the second one  can load user data into the cache before the exception occurs. Using  Flush+Reload data address can be identified.</p>
</li>
</ul>
<h3 id="meltdown"><a class="header" href="#meltdown">Meltdown:</a></h3>
<ul>
<li>This attack specifically tries to read kernel data from  userspace. It does this by trying to load a kernel address. The CPU loads the address and then raises an exception. This loads the data into the  cache which is then read using Flush+Reload. Similar to Spectre v3 but  the implementation is specific to Intel.</li>
</ul>
<h3 id="ridl"><a class="header" href="#ridl">RIDL:</a></h3>
<ul>
<li>Other parts of the CPU from which similar data can leak. <a href="https://mdsattacks.com/">https://mdsattacks.com/</a></li>
<li><a href="https://mdsattacks.com/slides/slides.html">https://mdsattacks.com/slides/slides.html</a></li>
</ul>
<h3 id="mitigations"><a class="header" href="#mitigations">Mitigations</a></h3>
<p>KAISER: an implementation to hide kernel data from userspace. <a href="https://lwn.net/Articles/738975/">Link</a></p>
<p>Meltdown and Spectre cause a performance Impact of 8 to 20% to IO intensive workloads, &lt;5 % impact on CPU intensive. (<a href="https://access.redhat.com/articles/3307751">Source</a>)</p>
<p>On my AMD Ryzen 5 PRO 3500U Laptop:</p>
<pre><code>$ grep . /sys/devices/system/cpu/vulnerabilities/*
itlb_multihit:Not affected
l1tf:Not affected
mds:Not affected
meltdown:Not affected
spec_store_bypass:Mitigation: Speculative Store Bypass disabled via prctl and seccomp
spectre_v1:Mitigation: usercopy/swapgs barriers and __user pointer sanitization
spectre_v2:Mitigation: Full AMD retpoline, IBPB: conditional, STIBP: disabled, RSB filling
tsx_async_abort:Not affected 
</code></pre>
<ul>
<li>Google zero blog <a href="https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html">link</a> .</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="m3-memory-models"><a class="header" href="#m3-memory-models">M3 Memory Models</a></h1>
<p>Notes from:</p>
<ul>
<li><a href="https://research.swtch.com/hwmm">Hardware Memory Models</a></li>
<li><a href="https://research.swtch.com/plmm">Programming Language Memory Models</a></li>
<li><a href="https://research.swtch.com/gomm">Updating the Go Memory Model</a></li>
</ul>
<hr />
<p>Memory model decides the visibility and consistency of changes to data stored in memory. The hardware's memory model helps developers understand what the hardware guarantees.</p>
<h2 id="m31-sequential-consistency"><a class="header" href="#m31-sequential-consistency">M3.1 Sequential Consistency</a></h2>
<p>Essentially, if processors are running instructions</p>
<ol>
<li>
<p>The order of instructions that a processor runs cannot be re-ordered. i.e. if a processor has instructions <code>I1, I2, I3</code> , they must be applied in the same order.</p>
</li>
<li>
<p>Instructions accross processors can interleave in any way while the condition <code>1</code> is not violated</p>
</li>
</ol>
<p>Mental model: Threads write to a shared memory, without any caches. Only one thread is allowed to read/write at a time.</p>
<p><img src="M/imgs/mem-sc.png" alt="img" /></p>
<h2 id="m32-x86-total-store-order-x86-tso"><a class="header" href="#m32-x86-total-store-order-x86-tso">M3.2 x86 Total Store Order (x86-TSO)</a></h2>
<p>All threads are connected to a shared memory, but:</p>
<ol>
<li>each processor queues writes into a local write buffer</li>
<li>each checks local write buffer before checking the shared memory.
<ol>
<li>i.e. a processor sees it writes before others do</li>
</ol>
</li>
<li>All processors <strong>agree on the total order of writes</strong> to the shared memory.
<ol>
<li>corollary:  If we have N reader threads and 1 writer thread, then all the readers MUST see the written value together. i.e. either they  all see the old value or all see the new value.</li>
</ol>
</li>
</ol>
<p><img src="M/imgs/mem-tso.png" alt="img" /></p>
<h2 id="m34-arm-relaxed-memory-model"><a class="header" href="#m34-arm-relaxed-memory-model">M3.4 ARM Relaxed Memory Model</a></h2>
<ul>
<li>Each processor reads/writes to its own copy of memory.</li>
<li>The writes are propagated to other threads independently. Writes can propagate with any reordering.</li>
<li>But write order is agreed by all the Threads. (i.e. it may happen at different times, but the order is the same)</li>
<li>Each thread can also postpone a read until after a write. i.e. reordering within a thread's instructions.</li>
</ul>
<p><img src="M/imgs/mem-weak.png" alt="img" /></p>
<h2 id="m34-litmus-tests"><a class="header" href="#m34-litmus-tests">M3.4 Litmus tests</a></h2>
<p>A series of tests to show cases where the memory models differ. In each test, threads read/write to shared values x,y,z... and read to thread local registers r1,r2,... </p>
<h5 id="m341-litmus-test-message-passing"><a class="header" href="#m341-litmus-test-message-passing">M3.4.1 Litmus test: Message Passing</a></h5>
<pre><code>// Thread 1            // Thread 2
x = 1                     r1 = y
y = 1                     r2 = x
</code></pre>
<p>Q. Can this program see <code>r1=1</code> and <code>r2=0</code>?</p>
<ul>
<li>Seq Consistency: NO
<ul>
<li>because writes in Thread 1 must happen in the same order</li>
</ul>
</li>
<li>TSO: NO
<ul>
<li>writes queue guarantees the x write happens before y write.</li>
</ul>
</li>
<li>ARM: YES</li>
</ul>
<h5 id="m342-litmus-test-write-queue"><a class="header" href="#m342-litmus-test-write-queue">M3.4.2 Litmus test: Write Queue</a></h5>
<pre><code>// Thread 1            // Thread 2
x = 1                     y = 1
r1 = y                    r2 = x
</code></pre>
<p>Q. Can this program see <code>r1 =0</code> and <code>r2 = 0</code>?</p>
<ul>
<li>Seq Consistency : NO
<ul>
<li>read to registers can only happen after atleast one of x or y are written.</li>
</ul>
</li>
<li>TSO: YES
<ul>
<li>if x and y writes are still in the queue, both processors can read old values.</li>
</ul>
</li>
<li>ARM: YES</li>
</ul>
<h5 id="m343-litmus-test-independent-reads-of-independent-writes-iriw"><a class="header" href="#m343-litmus-test-independent-reads-of-independent-writes-iriw">M3.4.3 Litmus Test: Independent Reads of Independent Writes (IRIW)</a></h5>
<pre><code>// Thread 1      // Thread 2      //Thread 3      //Thread 4
x = 1            y = 1            r1 = x          r3 = y
                                  r2 = y          r4 = x
</code></pre>
<p>Q. Can this program see <code>r1=1</code>, <code>r2=0</code>, <code>r3=1</code> and <code>r4=0</code> ?</p>
<ul>
<li>Seq Consistency: NO
<ul>
<li>writes to x and y must be appear to all threads in same order.</li>
</ul>
</li>
<li>TSO: NO
<ul>
<li>write order is agreed by all processors</li>
</ul>
</li>
<li>ARM: YES</li>
</ul>
<h5 id="m344-litmus-test-n6-paul-lowenstein"><a class="header" href="#m344-litmus-test-n6-paul-lowenstein">M3.4.4 Litmus Test: n6 (Paul Lowenstein)</a></h5>
<pre><code>// Thread 1         //Thread 2
x = 1               y = 1
r1 = x              x = 2
r2 = y
</code></pre>
<p>Q. Can this program see <code>r1=1</code>, <code>r2=0</code> and <code>x=1</code> ?</p>
<ul>
<li>Seq Consistency: NO</li>
<li>TSO: YES
<ul>
<li>x =1 is written, but y=1 and x=2 are still in the write queue.</li>
</ul>
</li>
<li>ARM: YES</li>
</ul>
<h5 id="m345-litmus-test-load-buffering"><a class="header" href="#m345-litmus-test-load-buffering">M3.4.5 Litmus Test: Load Buffering</a></h5>
<pre><code>// Thread 1         // Thread 2
r1 = x              r2 = y
y = 1               x = 1
</code></pre>
<p>Q. Can program see r1=1, r2=1?</p>
<ul>
<li>Seq Consistency: NO</li>
<li>TSO: NO</li>
<li>ARM: YES (can reorder reads)</li>
</ul>
<h5 id="m346-litmus-test-store-buffering"><a class="header" href="#m346-litmus-test-store-buffering">M3.4.6 Litmus Test: Store Buffering</a></h5>
<pre><code>// Thread 1            // Thread 2
x = 1                  y = 1
r1 = y                 r2 = x
</code></pre>
<p>Q. Can the program see r1=0, r2=0?</p>
<ul>
<li>Seq Consistent: NO</li>
<li>x86 TSO: YES</li>
<li>ARM: YES</li>
</ul>
<h5 id="m347-litmus-test-coherence"><a class="header" href="#m347-litmus-test-coherence">M3.4.7 Litmus Test: Coherence</a></h5>
<pre><code>//Thread 1        //Thread 2        //Thread 3        //Thread 4
x = 1             x = 2             r1 = x            r3 = x
                                    r2 = x            r4 = x
</code></pre>
<p>Q. Can the prohram see r1=1, r2=2, r3=2, r4=1 ?</p>
<ul>
<li>Seq Consistent: NO</li>
<li>x86 TSO: NO</li>
<li>ARM: NO</li>
</ul>
<h2 id="m35-weak-ordering-and-data-race-free-seq-consistency--drf-sc"><a class="header" href="#m35-weak-ordering-and-data-race-free-seq-consistency--drf-sc">M3.5 Weak Ordering and Data Race Free Seq. Consistency  (DRF-SC)</a></h2>
<ul>
<li>Proposed by Sarita Adve and Mark Hill in “<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.5567">Weak Ordering – A New Definition</a>”.</li>
<li>synchronization model : a set of constraints on memory accesses to specify how &amp; when synchronization needs to done</li>
<li>Hardware is weakly ordered w.r.t. a sync model IFF it appears seq. consistent to all software that obeys the sync. model.</li>
<li>One model that was proposed by the authors is Data-Race-Free (DRF) model.
<ul>
<li>DRF assumes HW has sync operations, other than read/write. 
<ul>
<li>a barrier is a sync-operation</li>
</ul>
</li>
<li>Then read/writes can be reordered but cannot be moved across a sync-operation.</li>
</ul>
</li>
<li>A program is DRF if two memory accesses are:
<ul>
<li>either both reads</li>
<li>Or accesses that are separated by sync operations, forcing one to happen before the other</li>
</ul>
</li>
<li>Weak Ordering: A contract between SW and HW that <strong>If SW is DRF, the HW acts as if it is sequentially consistent.</strong> This was proved by the authors
<ul>
<li>A recipe for HW designers &amp; SW developers to run sequentially consistent programs.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="p-papers"><a class="header" href="#p-papers">P. Papers</a></h1>
<p>Summaries of papers/talks that I read.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ml-systems"><a class="header" href="#ml-systems">ML Systems</a></h1>
<p>With the growth of ML models, a new set of systems problems are emerging. They involve:</p>
<ol>
<li>Distributed Learning: Running NN Learning algorithms across a fleet of machines.</li>
<li>ML Compilers</li>
<li>Custom Hardware for ML training and inference jobs</li>
</ol>
<h2 id="backlog-of-papers-yet-to-read"><a class="header" href="#backlog-of-papers-yet-to-read">Backlog of papers yet to read</a></h2>
<ol>
<li>Jupiter Evolving: <a href="https://dl.acm.org/doi/pdf/10.1145/3544216.3544265">Hochschild et al., 2021</a></li>
<li>TPUv4 <a href="https://arxiv.org/abs/2304.01433">Jouppi et al., 2023</a></li>
<li>TensorFlow <a href="https://arxiv.org/abs/1603.04467">Abadi et al.,</a></li>
<li>Pathways <a href="https://arxiv.org/abs/2203.12533">Barham et al., 2022</a></li>
<li>Cores that don't count <a href="https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s01-hochschild.pdf">Hochschild et al., 2021;</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="a-appendix"><a class="header" href="#a-appendix">A. Appendix</a></h1>
<p>These are a few links I think are useful.</p>
<ol>
<li>David Miller's <a href="http://vger.kernel.org/%7Edavem/skb.html">How SKBs work</a> and <a href="http://vger.kernel.org/%7Edavem/skb_data.html">skb data</a>. His home page has <a href="https://duckduckgo.com/?q=site%3A%22http%3A%2F%2Fvger.kernel.org%2F%7Edavem%2F%22+html">other useful links</a> as well.</li>
<li><a href="https://lwn.net">lwn.net</a> contains clean summaries. Search for links from site, e.g. lwn pages about <a href="https://duckduckgo.com/?q=site%3A%22lwn.net%22+ebpf">eBPF</a>.
<ol start="3">
<li>LWN page with Kernel related articles grouped by topic: <a href="https://lwn.net/Kernel/Index/">Kernel index</a>.</li>
</ol>
</li>
<li><a href="lartc.org">lartc.org</a> the best place for routing, traffic shaping, tunnelling info.</li>
<li>Twitter has a lot of active netdev members. <a href="https://twitter.com/tejaswi_tan/lists/netdev1">my list</a></li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
                
    </body>
</html>
